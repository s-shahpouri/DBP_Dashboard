{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-09 10:20:01.597 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\n",
      "2024-09-09 10:20:01.600 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import streamlit as st\n",
    "import plotly.graph_objs as go\n",
    "from plotly.subplots import make_subplots\n",
    "from vis import read_df, plot_interactive_boxplots_with_outliers, find_outliers, making_array, plot_img\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from vis import JsonProcessor, find_paths, extract_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PatientID</th>\n",
       "      <th>pred_0</th>\n",
       "      <th>pred_1</th>\n",
       "      <th>pred_2</th>\n",
       "      <th>true_0</th>\n",
       "      <th>true_1</th>\n",
       "      <th>true_2</th>\n",
       "      <th>0_dis</th>\n",
       "      <th>1_dis</th>\n",
       "      <th>2_dis</th>\n",
       "      <th>Euc_dis</th>\n",
       "      <th>L1_dis</th>\n",
       "      <th>L2_dis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OP022</td>\n",
       "      <td>-2.2358</td>\n",
       "      <td>-11.2743</td>\n",
       "      <td>-10.2784</td>\n",
       "      <td>1.6193</td>\n",
       "      <td>-9.0774</td>\n",
       "      <td>-11.0897</td>\n",
       "      <td>-3.8551</td>\n",
       "      <td>-2.1969</td>\n",
       "      <td>0.8113</td>\n",
       "      <td>4.510695</td>\n",
       "      <td>6.8633</td>\n",
       "      <td>20.346373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OP022</td>\n",
       "      <td>13.2915</td>\n",
       "      <td>6.9816</td>\n",
       "      <td>2.8148</td>\n",
       "      <td>11.4696</td>\n",
       "      <td>7.2543</td>\n",
       "      <td>4.8868</td>\n",
       "      <td>1.8219</td>\n",
       "      <td>-0.2727</td>\n",
       "      <td>-2.0720</td>\n",
       "      <td>2.772520</td>\n",
       "      <td>4.1666</td>\n",
       "      <td>7.686869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OP022</td>\n",
       "      <td>13.2552</td>\n",
       "      <td>8.8855</td>\n",
       "      <td>-0.5518</td>\n",
       "      <td>11.6152</td>\n",
       "      <td>8.8563</td>\n",
       "      <td>0.2965</td>\n",
       "      <td>1.6400</td>\n",
       "      <td>0.0292</td>\n",
       "      <td>-0.8483</td>\n",
       "      <td>1.846636</td>\n",
       "      <td>2.5175</td>\n",
       "      <td>3.410066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OP022</td>\n",
       "      <td>-8.4708</td>\n",
       "      <td>-11.4283</td>\n",
       "      <td>13.5931</td>\n",
       "      <td>-10.9469</td>\n",
       "      <td>-11.5725</td>\n",
       "      <td>12.9280</td>\n",
       "      <td>2.4761</td>\n",
       "      <td>0.1442</td>\n",
       "      <td>0.6651</td>\n",
       "      <td>2.567922</td>\n",
       "      <td>3.2854</td>\n",
       "      <td>6.594223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OP022</td>\n",
       "      <td>4.1765</td>\n",
       "      <td>-4.5389</td>\n",
       "      <td>8.9330</td>\n",
       "      <td>3.3624</td>\n",
       "      <td>-1.9916</td>\n",
       "      <td>11.1253</td>\n",
       "      <td>0.8141</td>\n",
       "      <td>-2.5473</td>\n",
       "      <td>-2.1923</td>\n",
       "      <td>3.457987</td>\n",
       "      <td>5.5537</td>\n",
       "      <td>11.957675</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PatientID   pred_0   pred_1   pred_2   true_0   true_1   true_2   0_dis  \\\n",
       "0     OP022  -2.2358 -11.2743 -10.2784   1.6193  -9.0774 -11.0897 -3.8551   \n",
       "1     OP022  13.2915   6.9816   2.8148  11.4696   7.2543   4.8868  1.8219   \n",
       "2     OP022  13.2552   8.8855  -0.5518  11.6152   8.8563   0.2965  1.6400   \n",
       "3     OP022  -8.4708 -11.4283  13.5931 -10.9469 -11.5725  12.9280  2.4761   \n",
       "4     OP022   4.1765  -4.5389   8.9330   3.3624  -1.9916  11.1253  0.8141   \n",
       "\n",
       "    1_dis   2_dis   Euc_dis  L1_dis     L2_dis  \n",
       "0 -2.1969  0.8113  4.510695  6.8633  20.346373  \n",
       "1 -0.2727 -2.0720  2.772520  4.1666   7.686869  \n",
       "2  0.0292 -0.8483  1.846636  2.5175   3.410066  \n",
       "3  0.1442  0.6651  2.567922  3.2854   6.594223  \n",
       "4 -2.5473 -2.1923  3.457987  5.5537  11.957675  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# File paths\n",
    "root = '/data/sama/Deep_Learning_Pipeline_Test/experiments_dose/test/20240828_060815_505_Dual_DCNN_LReLu_4_120_tr_1.057_val_1.462_test_2.676_avg_tr_1.024_val_2.116_test_2.997/'\n",
    "test_path = root + 'Dual_DCNN_LReLu_test_outputs.csv'\n",
    "val_path = root + 'Dual_DCNN_LReLu_val_outputs.csv'\n",
    "train_path = root + 'Dual_DCNN_LReLu_train_outputs.csv'\n",
    "\n",
    "# Load DataFrames\n",
    "df_test = read_df(test_path)\n",
    "df_train = read_df(train_path)\n",
    "df_val = read_df(val_path)\n",
    "\n",
    "# Dropdown for dataset selection\n",
    "dataset_option = 'test'\n",
    "\n",
    "# Load the selected DataFrame\n",
    "if dataset_option == 'train':\n",
    "    df = df_train\n",
    "elif dataset_option == 'val':\n",
    "    df = df_val\n",
    "else:\n",
    "    df = df_test\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-09 10:25:43.304 \"server.runOnsave\" is not a valid config option. If you previously had this config option set, it may have been removed.\n",
      "2024-09-09 10:25:43.305 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run /data/sama/env/lib64/python3.11/site-packages/ipykernel_launcher.py [ARGUMENTS]\n",
      "2024-09-09 10:25:43.306 No runtime found, using MemoryCacheStorageManager\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PatientID    0\n",
      "pred_0       0\n",
      "pred_1       0\n",
      "pred_2       0\n",
      "true_0       0\n",
      "true_1       0\n",
      "true_2       0\n",
      "0_dis        0\n",
      "1_dis        0\n",
      "2_dis        0\n",
      "Euc_dis      0\n",
      "L1_dis       0\n",
      "L2_dis       0\n",
      "fixed        0\n",
      "moving       0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PatientID</th>\n",
       "      <th>pred_0</th>\n",
       "      <th>pred_1</th>\n",
       "      <th>pred_2</th>\n",
       "      <th>true_0</th>\n",
       "      <th>true_1</th>\n",
       "      <th>true_2</th>\n",
       "      <th>0_dis</th>\n",
       "      <th>1_dis</th>\n",
       "      <th>2_dis</th>\n",
       "      <th>Euc_dis</th>\n",
       "      <th>L1_dis</th>\n",
       "      <th>L2_dis</th>\n",
       "      <th>fixed</th>\n",
       "      <th>moving</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OP022_rCTp17</td>\n",
       "      <td>-2.2358</td>\n",
       "      <td>-11.2743</td>\n",
       "      <td>-10.2784</td>\n",
       "      <td>1.6193</td>\n",
       "      <td>-9.0774</td>\n",
       "      <td>-11.0897</td>\n",
       "      <td>-3.8551</td>\n",
       "      <td>-2.1969</td>\n",
       "      <td>0.8113</td>\n",
       "      <td>4.510695</td>\n",
       "      <td>6.8633</td>\n",
       "      <td>20.346373</td>\n",
       "      <td>/data/bahrdoh/Datasets/Second_ds/nrrd/DBP_OP02...</td>\n",
       "      <td>/data/bahrdoh/Datasets/Second_ds/nrrd/DBP_OP02...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OP022_rCTp17</td>\n",
       "      <td>13.2915</td>\n",
       "      <td>6.9816</td>\n",
       "      <td>2.8148</td>\n",
       "      <td>11.4696</td>\n",
       "      <td>7.2543</td>\n",
       "      <td>4.8868</td>\n",
       "      <td>1.8219</td>\n",
       "      <td>-0.2727</td>\n",
       "      <td>-2.0720</td>\n",
       "      <td>2.772520</td>\n",
       "      <td>4.1666</td>\n",
       "      <td>7.686869</td>\n",
       "      <td>/data/bahrdoh/Datasets/Second_ds/nrrd/DBP_OP02...</td>\n",
       "      <td>/data/bahrdoh/Datasets/Second_ds/nrrd/DBP_OP02...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OP022_rCTp17</td>\n",
       "      <td>13.2552</td>\n",
       "      <td>8.8855</td>\n",
       "      <td>-0.5518</td>\n",
       "      <td>11.6152</td>\n",
       "      <td>8.8563</td>\n",
       "      <td>0.2965</td>\n",
       "      <td>1.6400</td>\n",
       "      <td>0.0292</td>\n",
       "      <td>-0.8483</td>\n",
       "      <td>1.846636</td>\n",
       "      <td>2.5175</td>\n",
       "      <td>3.410066</td>\n",
       "      <td>/data/bahrdoh/Datasets/Second_ds/nrrd/DBP_OP02...</td>\n",
       "      <td>/data/bahrdoh/Datasets/Second_ds/nrrd/DBP_OP02...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OP022_rCTp17</td>\n",
       "      <td>-8.4708</td>\n",
       "      <td>-11.4283</td>\n",
       "      <td>13.5931</td>\n",
       "      <td>-10.9469</td>\n",
       "      <td>-11.5725</td>\n",
       "      <td>12.9280</td>\n",
       "      <td>2.4761</td>\n",
       "      <td>0.1442</td>\n",
       "      <td>0.6651</td>\n",
       "      <td>2.567922</td>\n",
       "      <td>3.2854</td>\n",
       "      <td>6.594223</td>\n",
       "      <td>/data/bahrdoh/Datasets/Second_ds/nrrd/DBP_OP02...</td>\n",
       "      <td>/data/bahrdoh/Datasets/Second_ds/nrrd/DBP_OP02...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OP022_rCTp17</td>\n",
       "      <td>4.1765</td>\n",
       "      <td>-4.5389</td>\n",
       "      <td>8.9330</td>\n",
       "      <td>3.3624</td>\n",
       "      <td>-1.9916</td>\n",
       "      <td>11.1253</td>\n",
       "      <td>0.8141</td>\n",
       "      <td>-2.5473</td>\n",
       "      <td>-2.1923</td>\n",
       "      <td>3.457987</td>\n",
       "      <td>5.5537</td>\n",
       "      <td>11.957675</td>\n",
       "      <td>/data/bahrdoh/Datasets/Second_ds/nrrd/DBP_OP02...</td>\n",
       "      <td>/data/bahrdoh/Datasets/Second_ds/nrrd/DBP_OP02...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      PatientID   pred_0   pred_1   pred_2   true_0   true_1   true_2   0_dis  \\\n",
       "0  OP022_rCTp17  -2.2358 -11.2743 -10.2784   1.6193  -9.0774 -11.0897 -3.8551   \n",
       "1  OP022_rCTp17  13.2915   6.9816   2.8148  11.4696   7.2543   4.8868  1.8219   \n",
       "2  OP022_rCTp17  13.2552   8.8855  -0.5518  11.6152   8.8563   0.2965  1.6400   \n",
       "3  OP022_rCTp17  -8.4708 -11.4283  13.5931 -10.9469 -11.5725  12.9280  2.4761   \n",
       "4  OP022_rCTp17   4.1765  -4.5389   8.9330   3.3624  -1.9916  11.1253  0.8141   \n",
       "\n",
       "    1_dis   2_dis   Euc_dis  L1_dis     L2_dis  \\\n",
       "0 -2.1969  0.8113  4.510695  6.8633  20.346373   \n",
       "1 -0.2727 -2.0720  2.772520  4.1666   7.686869   \n",
       "2  0.0292 -0.8483  1.846636  2.5175   3.410066   \n",
       "3  0.1442  0.6651  2.567922  3.2854   6.594223   \n",
       "4 -2.5473 -2.1923  3.457987  5.5537  11.957675   \n",
       "\n",
       "                                               fixed  \\\n",
       "0  /data/bahrdoh/Datasets/Second_ds/nrrd/DBP_OP02...   \n",
       "1  /data/bahrdoh/Datasets/Second_ds/nrrd/DBP_OP02...   \n",
       "2  /data/bahrdoh/Datasets/Second_ds/nrrd/DBP_OP02...   \n",
       "3  /data/bahrdoh/Datasets/Second_ds/nrrd/DBP_OP02...   \n",
       "4  /data/bahrdoh/Datasets/Second_ds/nrrd/DBP_OP02...   \n",
       "\n",
       "                                              moving  \n",
       "0  /data/bahrdoh/Datasets/Second_ds/nrrd/DBP_OP02...  \n",
       "1  /data/bahrdoh/Datasets/Second_ds/nrrd/DBP_OP02...  \n",
       "2  /data/bahrdoh/Datasets/Second_ds/nrrd/DBP_OP02...  \n",
       "3  /data/bahrdoh/Datasets/Second_ds/nrrd/DBP_OP02...  \n",
       "4  /data/bahrdoh/Datasets/Second_ds/nrrd/DBP_OP02...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Usage example:\n",
    "json_processor = JsonProcessor(json_path=root + 'Data_dict_4.json')\n",
    "json_df = json_processor.get_dataframe()\n",
    "\n",
    "# Finding matched paths using the function\n",
    "df = find_paths(df, json_df)\n",
    "df['PatientID'] = df.apply(lambda row: f\"{row['PatientID']}_{extract_name(row['moving'])}\", axis=1)\n",
    "null_check = df.isnull().sum()\n",
    "print(null_check)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of 'Unknown' in PatientID: 0\n"
     ]
    }
   ],
   "source": [
    "unknown_count = df['PatientID'].str.contains('Unknown').sum()\n",
    "\n",
    "print(f\"Number of 'Unknown' in PatientID: {unknown_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find outliers for each difference and Euclidean distance\n",
    "outliers_diff_0 = find_outliers(df, 'diff_0')\n",
    "outliers_diff_1 = find_outliers(df, 'diff_1')\n",
    "outliers_diff_2 = find_outliers(df, 'diff_2')\n",
    "outliers_euclidean_dist = find_outliers(df, 'euclidean_dist')\n",
    "\n",
    "# Add a new column to each DataFrame indicating the type of difference\n",
    "outliers_diff_0['type'] = '0_dist'\n",
    "outliers_diff_1['type'] = '1_dist'\n",
    "outliers_diff_2['type'] = '2_dist'\n",
    "outliers_euclidean_dist['type'] = 'euclidean_dist'\n",
    "\n",
    "# Concatenate all DataFrames into one unique DataFrame\n",
    "outliers_df = pd.concat([outliers_diff_0, outliers_diff_1, outliers_diff_2, outliers_euclidean_dist])\n",
    "\n",
    "# Reset the index for the combined DataFrame\n",
    "outliers_df.reset_index(drop=True, inplace=True)\n",
    "outliers_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import numpy as np\n",
    "\n",
    "# Function to generate a word cloud with colors based on the values\n",
    "def plot_colored_wordcloud(data_dict, title):\n",
    "    # Normalize the values to a range between 0 and 1\n",
    "    min_val = min(data_dict.values())\n",
    "    max_val = max(data_dict.values())\n",
    "    norm_values = {k: (v - min_val) / (max_val - min_val) for k, v in data_dict.items()}\n",
    "    \n",
    "    # Define a colormap\n",
    "    colormap = plt.cm.viridis\n",
    "    \n",
    "    # Generate word cloud\n",
    "    wordcloud = WordCloud(width=400, height=200, background_color='white').generate_from_frequencies(data_dict)\n",
    "    \n",
    "    # Recolor the word cloud\n",
    "    def color_func(word, *args, **kwargs):\n",
    "        return mcolors.to_hex(colormap(norm_values[word]))\n",
    "\n",
    "    wordcloud = wordcloud.recolor(color_func=color_func)\n",
    "    \n",
    "    # Display the word cloud\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.title(title)\n",
    "    plt.colorbar(plt.cm.ScalarMappable(cmap=colormap, norm=plt.Normalize(vmin=min_val, vmax=max_val)), ax=plt.gca(), orientation='vertical')\n",
    "    plt.show()\n",
    "\n",
    "# Calculate the Mean Absolute Difference for each patient across coordinates\n",
    "mean_abs_diff_0 = df.groupby('PatientID')['diff_0'].apply(lambda x: abs(x).mean()).to_dict()\n",
    "mean_abs_diff_1 = df.groupby('PatientID')['diff_1'].apply(lambda x: abs(x).mean()).to_dict()\n",
    "mean_abs_diff_2 = df.groupby('PatientID')['diff_2'].apply(lambda x: abs(x).mean()).to_dict()\n",
    "mean_abs_diff_euclidean = df.groupby('PatientID')['euclidean_dist'].apply(lambda x: abs(x).mean()).to_dict()\n",
    "\n",
    "\n",
    "max_diff_0 = df.groupby('PatientID')['diff_0'].apply(lambda x: max(x)).to_dict()\n",
    "max_diff_1 = df.groupby('PatientID')['diff_1'].apply(lambda x: max(x)).to_dict()\n",
    "max_diff_2 = df.groupby('PatientID')['diff_2'].apply(lambda x: max(x)).to_dict()\n",
    "max_diff_euclidean = df.groupby('PatientID')['euclidean_dist'].apply(lambda x: max(x)).to_dict()\n",
    "\n",
    "# Plotting the word clouds with colors representing mean absolute differences and maximum values\n",
    "plot_colored_wordcloud(mean_abs_diff_0, 'Mean Absolute Differences in X-Axis (mm)')\n",
    "plot_colored_wordcloud(mean_abs_diff_1, 'Mean Absolute Differences in Y-Axis (mm)')\n",
    "plot_colored_wordcloud(mean_abs_diff_2, 'Mean Absolute Differences in Z-Axis (mm)')\n",
    "plot_colored_wordcloud(mean_abs_diff_euclidean, 'Mean Absolute Euclidean Distances (mm)')\n",
    "\n",
    "plot_colored_wordcloud(max_diff_0, 'Max of Absolute Differences in X-Axis (mm)')\n",
    "plot_colored_wordcloud(max_diff_1, 'Max of Absolute Differences in Y-Axis (mm)')\n",
    "plot_colored_wordcloud(max_diff_2, 'Max of Absolute Differences in Z-Axis (mm)')\n",
    "plot_colored_wordcloud(max_diff_euclidean, 'Max Euclidean Distances (mm)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------\n",
    "# Euclidean Distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " If your goal is to measure the absolute spatial error or displacement between predicted and actual points, Euclidean distance is likely the best choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Euclidean distances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Option 1: Sum of Euclidean distances for each PatientID\n",
    "# sum_dist = df_test.groupby('PatientID')['euclidean_dist'].sum().to_dict()\n",
    "\n",
    "# # Option 2: Maximum Euclidean distance for each PatientID\n",
    "# max_dist = df_test.groupby('PatientID')['euclidean_dist'].max().to_dict()\n",
    "\n",
    "# # Function to plot word cloud with colors\n",
    "# def plot_colored_wordcloud(data_dict, title):\n",
    "#     # Normalize the values to a range between 0 and 1\n",
    "#     min_val = min(data_dict.values())\n",
    "#     max_val = max(data_dict.values())\n",
    "#     norm_values = {k: (v - min_val) / (max_val - min_val) for k, v in data_dict.items()}\n",
    "    \n",
    "#     # Define a colormap\n",
    "#     colormap = plt.cm.viridis\n",
    "    \n",
    "#     # Generate word cloud\n",
    "#     wordcloud = WordCloud(width=800, height=400, background_color='white').generate_from_frequencies(data_dict)\n",
    "    \n",
    "#     # Recolor the word cloud\n",
    "#     def color_func(word, *args, **kwargs):\n",
    "#         return mcolors.to_hex(colormap(norm_values[word]))\n",
    "\n",
    "#     wordcloud = wordcloud.recolor(color_func=color_func)\n",
    "    \n",
    "#     # Display the word cloud\n",
    "#     plt.figure(figsize=(10, 5))\n",
    "#     plt.imshow(wordcloud, interpolation='bilinear')\n",
    "#     plt.axis('off')\n",
    "#     plt.title(title)\n",
    "#     plt.colorbar(plt.cm.ScalarMappable(cmap=colormap, norm=plt.Normalize(vmin=min_val, vmax=max_val)), ax=plt.gca(), orientation='vertical')\n",
    "#     plt.show()\n",
    "\n",
    "# # Plotting the word clouds for Euclidean distances\n",
    "# plot_colored_wordcloud(sum_dist, 'Sum of Euclidean Distances')\n",
    "# plot_colored_wordcloud(max_dist, 'Max of Euclidean Distances')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Assuming df_test contains the calculated differences and Euclidean distance for each row\n",
    "# # Add absolute differences columns if not already added\n",
    "# df_test['diff_0'] = df_test['diff_0']\n",
    "# df_test['diff_1'] = df_test['diff_1']\n",
    "# df_test['diff_2'] = df_test['diff_2']\n",
    "\n",
    "# # Prepare the data for the heatmap visualization\n",
    "# # Each row will be represented by the PatientID and the error metrics\n",
    "# heatmap_data = df_test[['PatientID', 'diff_0', 'diff_1', 'diff_2', 'euclidean_dist']]\n",
    "\n",
    "# # Plotting the heatmap for all rows\n",
    "# plt.figure(figsize=(5, 10))\n",
    "# sns.heatmap(heatmap_data.set_index('PatientID'), annot=False, cmap='seismic', linewidths=0.0)\n",
    "# plt.title('Heatmap of Errors')\n",
    "# plt.xlabel('Error Metric')\n",
    "# plt.ylabel('Patient ID')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "\n",
    "# # Example data: Replace with your actual CT pair names and their corresponding errors\n",
    "# ct_pairs = ['CT_Pair_{}'.format(i) for i in range(1, 21)]\n",
    "# errors = [2.5, 1.2, 3.7, 0.9, 4.1, 2.8, 1.0, 3.3, 1.5, 0.7, 2.1, 4.5, 3.9, 0.5, 1.7, 2.4, 0.8, 3.1, 2.2, 1.3]\n",
    "\n",
    "# fig = plt.figure(figsize=(12, 8))\n",
    "# ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# # Generate bar plot\n",
    "# x_pos = np.arange(len(ct_pairs))\n",
    "# y_pos = np.zeros(len(ct_pairs))\n",
    "# z_pos = np.zeros(len(ct_pairs))\n",
    "# dx = np.ones(len(ct_pairs))\n",
    "# dy = np.ones(len(ct_pairs))\n",
    "# dz = errors\n",
    "\n",
    "# ax.bar3d(x_pos, y_pos, z_pos, dx, dy, dz, color='b', zsort='average')\n",
    "\n",
    "# ax.set_xlabel('CT Pairs')\n",
    "# ax.set_ylabel('Y')\n",
    "# ax.set_zlabel('Error Magnitude')\n",
    "# ax.set_xticks(x_pos)\n",
    "# ax.set_xticklabels(ct_pairs, rotation=90)\n",
    "# plt.title(\"3D Bar Plot of Prediction Errors for CT Pairs\")\n",
    "\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "\n",
    "# # Example data: Replace with your actual CT pair names and their corresponding errors\n",
    "# ct_pairs = ['CT_Pair_{}'.format(i) for i in range(1, 21)]\n",
    "# errors = [2.5, 1.2, 3.7, 0.9, 4.1, 2.8, 1.0, 3.3, 1.5, 0.7, 2.1, 4.5, 3.9, 0.5, 1.7, 2.4, 0.8, 3.1, 2.2, 1.3]\n",
    "\n",
    "# # Number of variables\n",
    "# num_vars = len(ct_pairs)\n",
    "\n",
    "# # Compute angle of each axis\n",
    "# angles = np.linspace(0, 2 * np.pi, num_vars, endpoint=False).tolist()\n",
    "\n",
    "# # The plot is a circle, so we need to \"complete the loop\" and append the start value to the end.\n",
    "# errors += errors[:1]\n",
    "# angles += angles[:1]\n",
    "\n",
    "# # Plot\n",
    "# fig, ax = plt.subplots(figsize=(10, 10), subplot_kw=dict(polar=True))\n",
    "# ax.fill(angles, errors, color='blue', alpha=0.25)\n",
    "# ax.plot(angles, errors, color='blue', linewidth=2)\n",
    "\n",
    "# # Labels\n",
    "# ax.set_yticklabels([])\n",
    "# ax.set_xticks(angles[:-1])\n",
    "# ax.set_xticklabels(ct_pairs, rotation=90)\n",
    "\n",
    "# plt.title(\"Radar Chart of Prediction Errors for CT Pairs\")\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Assuming df_test contains the calculated differences for each row\n",
    "\n",
    "# # Plotting histograms for each set of differences separately\n",
    "# plt.figure(figsize=(15, 10))\n",
    "\n",
    "# # Histogram for X-axis differences (diff_0)\n",
    "# plt.subplot(2, 2, 1)\n",
    "# plt.hist(df_test['diff_0'], bins=30, color='lightblue', edgecolor='black')\n",
    "# plt.title('Histogram of Differences in X-Axis (diff_0)')\n",
    "# plt.xlabel('Difference')\n",
    "# plt.ylabel('Frequency')\n",
    "# plt.grid(True)\n",
    "\n",
    "# # Histogram for Y-axis differences (diff_1)\n",
    "# plt.subplot(2, 2, 2)\n",
    "# plt.hist(df_test['diff_1'], bins=30, color='lightgreen', edgecolor='black')\n",
    "# plt.title('Histogram of Differences in Y-Axis (diff_1)')\n",
    "# plt.xlabel('Difference')\n",
    "# plt.ylabel('Frequency')\n",
    "# plt.grid(True)\n",
    "\n",
    "# # Histogram for Z-axis differences (diff_2)\n",
    "# plt.subplot(2, 2, 3)\n",
    "# plt.hist(df_test['diff_2'], bins=30, color='lightcoral', edgecolor='black')\n",
    "# plt.title('Histogram of Differences in Z-Axis (diff_2)')\n",
    "# plt.xlabel('Difference')\n",
    "# plt.ylabel('Frequency')\n",
    "# plt.grid(True)\n",
    "\n",
    "# # Histogram for Euclidean distances\n",
    "# plt.subplot(2, 2, 4)\n",
    "# plt.hist(df_test['euclidean_dist'], bins=30, color='lightgrey', edgecolor='black')\n",
    "# plt.title('Histogram of Euclidean Distances')\n",
    "# plt.xlabel('Distance')\n",
    "# plt.ylabel('Frequency')\n",
    "# plt.grid(True)\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming df_test contains the Euclidean distances or other differences\n",
    "data = df_test['euclidean_dist']\n",
    "\n",
    "# Q-Q plot for normal distribution\n",
    "stats.probplot(data, dist=\"norm\", plot=plt)\n",
    "plt.title(\"Q-Q Plot for Normal Distribution\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import shapiro\n",
    "\n",
    "# Perform Shapiro-Wilk test for normality\n",
    "stat, p = shapiro(data)\n",
    "print('Shapiro-Wilk Test Statistic:', stat)\n",
    "print('p-value:', p)\n",
    "\n",
    "if p > 0.05:\n",
    "    print(\"Data is normally distributed\")\n",
    "else:\n",
    "    print(\"Data is not normally distributed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import kstest\n",
    "\n",
    "# Perform K-S test against a normal distribution\n",
    "stat, p = kstest(data, 'norm', args=(data.mean(), data.std()))\n",
    "print('K-S Test Statistic:', stat)\n",
    "print('p-value:', p)\n",
    "\n",
    "if p > 0.05:\n",
    "    print(\"Data is similar to a normal distribution\")\n",
    "else:\n",
    "    print(\"Data is not similar to a normal distribution\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "skewness = skew(data)\n",
    "kurt = kurtosis(data)\n",
    "print(f\"Skewness: {skewness}\")\n",
    "print(f\"Kurtosis: {kurt}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpretation:\n",
    "Normal Distribution: A normal Q-Q plot will show points falling on a straight line. Shapiro-Wilk, K-S, or other tests will have a high p-value (typically > 0.05), indicating normality.\n",
    "Poisson Distribution: Q-Q plots and specific tests (not shown above) can check for Poisson characteristics. The data will often exhibit integer counts with variance close to the mean.\n",
    "Other Distributions: Fit the data to different distributions and compare using AIC/BIC to find the best fit.\n",
    "\n",
    "************************************************************\n",
    "\n",
    " The results you've provided from various statistical tests and measures offer insight into the distribution of your data. Here's the interpretation:\n",
    "\n",
    "1. Shapiro-Wilk Test:\n",
    "Statistic: 0.9803\n",
    "p-value: 0.00022\n",
    "The Shapiro-Wilk test is a common test for normality. The null hypothesis of the test is that the data is normally distributed. In this case, the p-value is significantly less than 0.05, leading us to reject the null hypothesis. Therefore, according to the Shapiro-Wilk test, the data does not follow a normal distribution.\n",
    "\n",
    "2. Kolmogorov-Smirnov (K-S) Test:\n",
    "Statistic: 0.0571\n",
    "p-value: 0.2388\n",
    "The K-S test compares the sample data with a reference probability distribution (here, a normal distribution). The null hypothesis is that the sample follows the reference distribution. The p-value is greater than 0.05, which means we do not reject the null hypothesis. Thus, according to the K-S test, there is no significant evidence to say that the data is not normally distributed.\n",
    "\n",
    "3. Skewness:\n",
    "Value: 0.4289\n",
    "Skewness measures the asymmetry of the distribution. A skewness close to 0 indicates a symmetric distribution. Positive skewness (0.4289) suggests a slight right-skew (tail on the right side), meaning there are a few unusually high values.\n",
    "\n",
    "4. Kurtosis:\n",
    "Value: -0.3410\n",
    "Kurtosis measures the \"tailedness\" of the distribution. A normal distribution has a kurtosis of 0. Negative kurtosis (platykurtic) indicates that the data has lighter tails than a normal distribution, suggesting fewer outliers.\n",
    "\n",
    "Overall Interpretation:\n",
    "The Shapiro-Wilk test indicates that the data is not normally distributed, as evidenced by the low p-value.\n",
    "The K-S test, however, suggests that the data is similar to a normal distribution, though this conclusion might be less robust due to the test's sensitivity to sample size and differences between sample and population distributions.\n",
    "The skewness and kurtosis values suggest that the data is slightly right-skewed with less prominent tails than a normal distribution.\n",
    "Reconciling the Tests:\n",
    "\n",
    "While the Shapiro-Wilk test indicates non-normality, the K-S test and the shape descriptors (skewness and kurtosis) do not strongly suggest significant deviations from normality. This discrepancy can arise from the tests' different sensitivities to various aspects of the data distribution. The K-S test, in particular, is not as sensitive to deviations in the tails as the Shapiro-Wilk test.\n",
    "\n",
    "Conclusion:\n",
    "\n",
    "While there are indications that the data does not perfectly follow a normal distribution (based on the Shapiro-Wilk test and slight skewness), the deviations are not extreme. Depending on your specific analysis requirements, you might consider treating the data as approximately normal, especially if your sample size is large, which can justify the use of normal-based methods due to the Central Limit Theorem. However, if precise normality is crucial, these results suggest that normality cannot be strictly assumed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Example data: Replace with your actual patient IDs and their corresponding Euclidean distances\n",
    "# patient_ids = df_test['PatientID']\n",
    "# euclidean_distances = df_test['euclidean_dist']\n",
    "\n",
    "# # Generate bubble chart\n",
    "# plt.figure(figsize=(12, 8))\n",
    "# bubble_size = [distance * 100 for distance in euclidean_distances]  # Adjust the bubble size as needed\n",
    "# plt.scatter(patient_ids, euclidean_distances, s=bubble_size, alpha=0.1, c='blue')\n",
    "# plt.xticks(rotation=90)\n",
    "# plt.xlabel(\"Patient IDs\")\n",
    "# plt.ylabel(\"Euclidean Distance (mm)\")\n",
    "# plt.title(\"Bubble Chart of Euclidean Distances\")\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# def plot_boxplots_with_outliers(df_test, outliers_df):\n",
    "#     \"\"\"\n",
    "#     Plots box plots with labeled outliers for the provided metrics.\n",
    "\n",
    "#     Parameters:\n",
    "#     - df_test: DataFrame containing the test data with metrics.\n",
    "#     - outliers_df: DataFrame containing the combined outliers data with the type of difference.\n",
    "#     \"\"\"\n",
    "#     plt.figure(figsize=(16, 6))\n",
    "\n",
    "#     # Extract different types of outliers\n",
    "#     outliers_diff_0 = outliers_df[outliers_df['type'] == '0_dist']\n",
    "#     outliers_diff_1 = outliers_df[outliers_df['type'] == '1_dist']\n",
    "#     outliers_diff_2 = outliers_df[outliers_df['type'] == '2_dist']\n",
    "#     outliers_euclidean = outliers_df[outliers_df['type'] == 'euclidean_dist']\n",
    "\n",
    "#     # Box plot for diff_0\n",
    "#     plt.subplot(1, 4, 1)\n",
    "#     plt.boxplot(df_test['diff_0'], flierprops={'marker': 'o', 'color': 'red', 'markersize': 8})\n",
    "#     plt.text(0.5, -0.2, 'Difference in X (diff_0)', ha='center', transform=plt.gca().transAxes)\n",
    "#     plt.ylabel('Values')\n",
    "\n",
    "#     # Labeling outliers for diff_0\n",
    "#     for i, row in outliers_diff_0.iterrows():\n",
    "#         plt.text(1.05, row['diff_0'], row['PatientID'], fontsize=9)\n",
    "\n",
    "#     # Box plot for diff_1\n",
    "#     plt.subplot(1, 4, 2)\n",
    "#     plt.boxplot(df_test['diff_1'], flierprops={'marker': 'o', 'color': 'red', 'markersize': 8})\n",
    "#     plt.text(0.5, -0.2, 'Difference in Y (diff_1)', ha='center', transform=plt.gca().transAxes)\n",
    "\n",
    "#     # Labeling outliers for diff_1\n",
    "#     for i, row in outliers_diff_1.iterrows():\n",
    "#         plt.text(1.05, row['diff_1'], row['PatientID'], fontsize=9)\n",
    "\n",
    "#     # Box plot for diff_2\n",
    "#     plt.subplot(1, 4, 3)\n",
    "#     plt.boxplot(df_test['diff_2'], flierprops={'marker': 'o', 'color': 'red', 'markersize': 8})\n",
    "#     plt.text(0.5, -0.2, 'Difference in Z (diff_2)', ha='center', transform=plt.gca().transAxes)\n",
    "\n",
    "#     # Labeling outliers for diff_2\n",
    "#     for i, row in outliers_diff_2.iterrows():\n",
    "#         plt.text(1.05, row['diff_2'], row['PatientID'], fontsize=9)\n",
    "\n",
    "#     # Box plot for Euclidean distances\n",
    "#     plt.subplot(1, 4, 4)\n",
    "#     plt.boxplot(df_test['euclidean_dist'], flierprops={'marker': 'o', 'color': 'red', 'markersize': 8})\n",
    "#     plt.text(0.5, -0.2, 'Euclidean Distance', ha='center', transform=plt.gca().transAxes)\n",
    "\n",
    "#     # Labeling outliers for Euclidean distances\n",
    "#     for i, row in outliers_euclidean.iterrows():\n",
    "#         plt.text(1.05, row['euclidean_dist'], row['PatientID'], fontsize=9)\n",
    "\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "\n",
    "# # Example usage:\n",
    "# plot_boxplots_with_outliers(df_test, outliers_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import plotly.graph_objs as go\n",
    "# from plotly.subplots import make_subplots\n",
    "\n",
    "# def plot_interactive_boxplots_with_outliers(df_test, outliers_df):\n",
    "#     # Create subplots\n",
    "#     fig = make_subplots(rows=1, cols=4, subplot_titles=['Difference in X (diff_0)', 'Difference in Y (diff_1)', 'Difference in Z (diff_2)', 'Euclidean Distance'])\n",
    "\n",
    "#     # Add box plots\n",
    "#     fig.add_trace(go.Box(y=df_test['diff_0'], name='diff_0', boxpoints='outliers', marker=dict(color='blue')), row=1, col=1)\n",
    "#     fig.add_trace(go.Box(y=df_test['diff_1'], name='diff_1', boxpoints='outliers', marker=dict(color='blue')), row=1, col=2)\n",
    "#     fig.add_trace(go.Box(y=df_test['diff_2'], name='diff_2', boxpoints='outliers', marker=dict(color='blue')), row=1, col=3)\n",
    "#     fig.add_trace(go.Box(y=df_test['euclidean_dist'], name='euclidean_dist', boxpoints='outliers', marker=dict(color='blue')), row=1, col=4)\n",
    "\n",
    "#     # Add outliers as scatter points with additional information\n",
    "#     for i, row in outliers_df.iterrows():\n",
    "#         hover_text = (f\"Patient ID: {row['PatientID']}<br>True Coords: ({row['true_0']}, {row['true_1']}, {row['true_2']})<br>\"\n",
    "#                       f\"Pred Coords: ({row['pred_0']}, {row['pred_1']}, {row['pred_2']})<br>Diff: {row['type']}\")\n",
    "\n",
    "#         if row['type'] == '0_dist':\n",
    "#             fig.add_trace(go.Scatter(x=['diff_0'], y=[row['diff_0']],\n",
    "#                                      mode='markers',\n",
    "#                                      marker=dict(color='red', size=10),\n",
    "#                                      text=row['PatientID'],\n",
    "#                                      hovertext=hover_text,\n",
    "#                                      hoverinfo='text'), row=1, col=1)\n",
    "#         elif row['type'] == '1_dist':\n",
    "#             fig.add_trace(go.Scatter(x=['diff_1'], y=[row['diff_1']],\n",
    "#                                      mode='markers',\n",
    "#                                      marker=dict(color='red', size=10),\n",
    "#                                      text=row['PatientID'],\n",
    "#                                      hovertext=hover_text,\n",
    "#                                      hoverinfo='text'), row=1, col=2)\n",
    "#         elif row['type'] == '2_dist':\n",
    "#             fig.add_trace(go.Scatter(x=['diff_2'], y=[row['diff_2']],\n",
    "#                                      mode='markers',\n",
    "#                                      marker=dict(color='red', size=10),\n",
    "#                                      text=row['PatientID'],\n",
    "#                                      hovertext=hover_text,\n",
    "#                                      hoverinfo='text'), row=1, col=3)\n",
    "#         elif row['type'] == 'euclidean_dist':\n",
    "#             fig.add_trace(go.Scatter(x=['euclidean_dist'], y=[row['euclidean_dist']],\n",
    "#                                      mode='markers',\n",
    "#                                      marker=dict(color='red', size=10),\n",
    "#                                      text=row['PatientID'],\n",
    "#                                      hovertext=hover_text,\n",
    "#                                      hoverinfo='text'), row=1, col=4)\n",
    "\n",
    "#     # Update layout for aesthetics\n",
    "#     fig.update_layout(height=600, width=1400, title_text=\"Box plots of differences with outliers\",\n",
    "#                       showlegend=False)\n",
    "#     # Update layout for aesthetics\n",
    "#     fig.update_layout(height=600, width=1400, title_text=\"Box plots of differences with outliers\",\n",
    "#                       showlegend=False)\n",
    "#     # fig.update_traces(quartilemethod=\"exclusive\") # or \"inclusive\", or \"linear\" by default\n",
    "\n",
    "#     fig.show()\n",
    "\n",
    "# # Example usage:\n",
    "# plot_interactive_boxplots_with_outliers(df_test, outliers_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import plotly.graph_objs as go\n",
    "# from plotly.subplots import make_subplots\n",
    "\n",
    "# def plot_interactive_boxplots_with_outliers(df_test, outliers_df):\n",
    "#     # Create subplots\n",
    "#     fig = make_subplots(rows=1, cols=4, subplot_titles=[\n",
    "#         'Difference in X (diff_0)', 'Difference in Y (diff_1)', 'Difference in Z (diff_2)', 'Euclidean Distance'\n",
    "#     ])\n",
    "\n",
    "#     # # Add box plots for all points\n",
    "#     # fig.add_trace(go.Box(y=df_test['diff_0'], name='All Points (diff_0)', boxpoints='all', \n",
    "#     #                     marker=dict(color='rgba(6, 40, 89, 0.2)'), line_color='rgb(7,40,89)'), row=1, col=1)\n",
    "#     # fig.add_trace(go.Box(y=df_test['diff_1'], name='All Points (diff_1)', boxpoints='all', \n",
    "#     #                     marker=dict(color='rgba(7, 40, 89, 0.2)'), line_color='rgb(7,40,89)'), row=1, col=2)\n",
    "#     # fig.add_trace(go.Box(y=df_test['diff_2'], name='All Points (diff_2)', boxpoints='all', \n",
    "#     #                     marker=dict(color='rgba(7, 40, 89, 0.2)'), line_color='rgb(7,40,89)'), row=1, col=3)\n",
    "#     # fig.add_trace(go.Box(y=df_test['euclidean_dist'], name='All Points (euclidean_dist)', boxpoints='all', \n",
    "#     #                     marker=dict(color='rgba(7, 40, 89, 0.2)'), line_color='rgb(7,40,89)'), row=1, col=4)\n",
    "\n",
    "#     # Add box plots\n",
    "#     fig.add_trace(go.Box(y=df_test['diff_0'], name='diff_0', boxpoints='suspectedoutliers',\n",
    "#                          marker=dict(color='rgb(8,81,156)', outliercolor='rgba(219, 64, 82, 0.6)', \n",
    "#                         line=dict(outliercolor='rgba(219, 64, 82, 0.6)', outlierwidth=2)), \n",
    "#                          line_color='rgb(8,81,156)'), row=1, col=1)\n",
    "#     fig.add_trace(go.Box(y=df_test['diff_1'], name='diff_1', boxpoints='suspectedoutliers',\n",
    "#                         marker=dict(color='rgb(8,81,156)', outliercolor='rgba(219, 64, 82, 0.6)', \n",
    "#                         line=dict(outliercolor='rgba(219, 64, 82, 0.6)', outlierwidth=2)), \n",
    "#                          line_color='rgb(8,81,156)'), row=1, col=2)\n",
    "#     fig.add_trace(go.Box(y=df_test['diff_2'], name='diff_2', boxpoints='suspectedoutliers',\n",
    "#                         marker=dict(color='rgb(8,81,156)', outliercolor='rgba(219, 64, 82, 0.6)', \n",
    "#                         line=dict(outliercolor='rgba(219, 64, 82, 0.6)', outlierwidth=2)), \n",
    "#                          line_color='rgb(8,81,156)'), row=1, col=3)\n",
    "#     fig.add_trace(go.Box(y=df_test['euclidean_dist'], name='euclidean_dist', boxpoints='suspectedoutliers',\n",
    "#                         marker=dict(color='rgb(8,81,156)', outliercolor='rgba(219, 64, 82, 0.6)', \n",
    "#                         line=dict(outliercolor='rgba(219, 64, 82, 0.6)', outlierwidth=2)), \n",
    "#                          line_color='rgb(8,81,156)'), row=1, col=4)\n",
    "\n",
    "\n",
    "#     # Update layout for aesthetics\n",
    "#     fig.update_layout(height=600, width=1400, title_text=\"Box plots of differences with detailed outliers\",\n",
    "#                       showlegend=True)\n",
    "\n",
    "#     return fig\n",
    "\n",
    "# # Example usage:\n",
    "# fig = plot_interactive_boxplots_with_outliers(df_test, outliers_df)\n",
    "# fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objs as go\n",
    "from plotly.subplots import make_subplots\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def plot_boxplots_with_outliers(df_test):\n",
    "    N = 8\n",
    "    \n",
    "    # Generate an array of rainbow colors\n",
    "    colors = ['hsl('+str(h)+',50%'+',50%)' for h in np.linspace(0, 360, N)]\n",
    "\n",
    "    # Create subplots\n",
    "    fig = make_subplots(rows=1, cols=4, subplot_titles=[\n",
    "        'Difference in X (diff_0)', 'Difference in Y (diff_1)', 'Difference in Z (diff_2)', 'Euclidean Distance'\n",
    "    ])\n",
    "\n",
    "    # Add strip plots (scatter plots) for all points with manual jitter\n",
    "    jitter_amount = 0.1\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=np.random.normal(1, jitter_amount, size=len(df_test['diff_0'])),\n",
    "        y=df_test['diff_0'], mode='markers', name='All Points (diff_0)', \n",
    "        marker=dict(color=colors[0], size=5, opacity=0.3)), row=1, col=1)\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=np.random.normal(2, jitter_amount, size=len(df_test['diff_1'])),\n",
    "        y=df_test['diff_1'], mode='markers', name='All Points (diff_1)', \n",
    "        marker=dict(color=colors[2], size=5, opacity=0.3)), row=1, col=2)\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=np.random.normal(3, jitter_amount, size=len(df_test['diff_2'])),\n",
    "        y=df_test['diff_2'], mode='markers', name='All Points (diff_2)', \n",
    "        marker=dict(color=colors[5], size=5, opacity=0.3)), row=1, col=3)\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=np.random.normal(4, jitter_amount, size=len(df_test['euclidean_dist'])),\n",
    "        y=df_test['euclidean_dist'], mode='markers', name='All Points (euclidean_dist)', \n",
    "        marker=dict(color=colors[6], size=5, opacity=0.3)), row=1, col=4)\n",
    "\n",
    "    # Add box plots for suspected outliers using different colors\n",
    "    fig.add_trace(go.Box(y=df_test['diff_0'], name='Box (diff_0)', boxpoints='suspectedoutliers',\n",
    "                         marker=dict(color=colors[0])), row=1, col=1)\n",
    "    fig.add_trace(go.Box(y=df_test['diff_1'], name='Box (diff_1)', boxpoints='suspectedoutliers',\n",
    "                         marker=dict(color=colors[2])), row=1, col=2)\n",
    "    fig.add_trace(go.Box(y=df_test['diff_2'], name='Box (diff_2)', boxpoints='suspectedoutliers',\n",
    "                         marker=dict(color=colors[5])), row=1, col=3)\n",
    "    fig.add_trace(go.Box(y=df_test['euclidean_dist'], name='Box (euclidean_dist)', boxpoints='suspectedoutliers',\n",
    "                         marker=dict(color=colors[6])), row=1, col=4)\n",
    "\n",
    "    # Update layout for aesthetics\n",
    "    fig.update_layout(height=600, width=1400, title_text=\"Box and Strip Plots of Differences with Outliers\",\n",
    "                      showlegend=False)\n",
    "    fig.update_xaxes(showticklabels=False)\n",
    "    return fig\n",
    "\n",
    "# Example usage:\n",
    "fig = plot_boxplots_with_outliers(df)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def visualize_ct_comparison(outlier, slice_index=50, colormap='jet'):\n",
    "#     fixed_CT_image = itk.imread(outlier['fixed'])  # Load the fixed image\n",
    "#     moving_CT_image = itk.imread(outlier['moving'])  # Load the moving image\n",
    "\n",
    "#     # True and predicted coordinates from the outlier data\n",
    "#     true_coords = [outlier['true_0'], outlier['true_1'], outlier['true_2']]\n",
    "#     pred_coords = [outlier['pred_0'], outlier['pred_1'], outlier['pred_2']]\n",
    "#     pixdim = fixed_CT_image.GetSpacing()  # Assuming the pixel dimensions are the same for both images\n",
    "\n",
    "#     # Transform the moving image based on true coordinates\n",
    "#     transformed_moving_CT_array_true = transform_moving_ct(\n",
    "#                     moving_CT_image, fixed_CT_image, true_coords, pixdim)\n",
    "#     # Transform the moving image based on predicted coordinates\n",
    "#     transformed_moving_CT_array_pred = transform_moving_ct(\n",
    "#                     moving_CT_image, fixed_CT_image, pred_coords, pixdim)\n",
    "\n",
    "#     # Calculate the difference between the fixed image and transformed moving images (true and predicted coordinates)\n",
    "#     fixed_CT_array = itk.array_view_from_image(fixed_CT_image)\n",
    "#     moving_CT_array = itk.array_view_from_image(moving_CT_image)\n",
    "#     difference_true = transformed_moving_CT_array_true - fixed_CT_array\n",
    "#     difference_pred = transformed_moving_CT_array_pred - fixed_CT_array\n",
    "\n",
    "#     # Define a scaling factor for the colorbar (e.g., 1000 for x10^3)\n",
    "#     scaling_factor = 1000.0\n",
    "\n",
    "#     # Plotting the results in a 2-row, 3-column layout with colorbars\n",
    "#     plt.figure(figsize=(8,8))\n",
    "\n",
    "#     def add_subplot_with_colorbar(index, data, title):\n",
    "#         plt.subplot(3, 2, index)\n",
    "#         scaled_data = data[slice_index] / scaling_factor  # Scale the data\n",
    "#         img = plt.imshow(scaled_data, cmap=colormap)\n",
    "#         cbar = plt.colorbar(img, fraction=0.03, pad=0.03)\n",
    "#         cbar.ax.set_title(f'     x10^{int(np.log10(scaling_factor))}', fontsize=10)\n",
    "#         plt.title(title)\n",
    "\n",
    "#     add_subplot_with_colorbar(1, fixed_CT_array, 'Fixed Image')\n",
    "#     add_subplot_with_colorbar(2, moving_CT_array, 'Moving Image')\n",
    "#     add_subplot_with_colorbar(3, transformed_moving_CT_array_true, 'Transformed Moving (True)')\n",
    "#     add_subplot_with_colorbar(4, difference_true, 'Difference for (True coordination)')\n",
    "#     add_subplot_with_colorbar(5, transformed_moving_CT_array_pred, 'Transformed Moving (Pred)')\n",
    "#     add_subplot_with_colorbar(6, difference_pred, 'Difference for (Pred coordinatoion)')\n",
    "\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "\n",
    "# # Example usage with the first outlier\n",
    "# outlier = outliers.iloc[0]\n",
    "# visualize_ct_comparison(outlier, slice_index=50, colormap='jet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from vis import transform_moving_ct, making_array\n",
    "\n",
    "outlier = outliers_df.iloc[0]\n",
    "data = making_array (outlier)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------\n",
    "# making a dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Version without considering the different choises for one patinet name\n",
    "# import ipywidgets as widgets\n",
    "# from IPython.display import display, clear_output\n",
    "# import matplotlib.pyplot as plt\n",
    "# import pandas as pd\n",
    "\n",
    "# # Assuming df_test contains the calculated differences and PatientID for each row\n",
    "# # Assuming outliers_df is the DataFrame containing outliers with 'PatientID' and 'type'\n",
    "\n",
    "# # Initialize UI elements\n",
    "# diff_selector = widgets.Dropdown(options=['0_dist', '1_dist', '2_dist', 'euclidean_dist'], description='Mode:')\n",
    "# outlier_selector = widgets.Dropdown(description='Outlier:')\n",
    "# plot_button = widgets.Button(description='Show CT Comparison')\n",
    "\n",
    "# # Output widget for plots\n",
    "# output = widgets.Output()\n",
    "\n",
    "# def update_outliers(*args):\n",
    "#     diff_mode = diff_selector.value\n",
    "#     # Filter the outliers_df based on the selected mode\n",
    "#     outliers_filtered = outliers_df[outliers_df['type'] == diff_mode]\n",
    "#     # Update the outlier_selector options with unique PatientIDs\n",
    "#     outlier_selector.options = list(outliers_filtered['PatientID'].unique())\n",
    "\n",
    "# # Call the update function initially to set default values\n",
    "# update_outliers()\n",
    "\n",
    "# # Observe changes in the diff_selector to update outlier_selector\n",
    "# diff_selector.observe(update_outliers, 'value')\n",
    "\n",
    "# def on_plot_button_clicked(b):\n",
    "#     selected_patient_id = outlier_selector.value\n",
    "#     selected_diff_mode = diff_selector.value\n",
    "    \n",
    "#     # Select the specific outlier based on PatientID and difference type\n",
    "#     selected_outlier = outliers_df[\n",
    "#         (outliers_df['PatientID'] == selected_patient_id) &\n",
    "#         (outliers_df['type'] == selected_diff_mode)\n",
    "#     ]\n",
    "\n",
    "#     if not selected_outlier.empty:\n",
    "#         outlier = selected_outlier.iloc[0].to_dict()\n",
    "#         data = making_array(outlier)\n",
    "        \n",
    "#         with output:\n",
    "#             # Clear previous output\n",
    "#             clear_output(wait=True)\n",
    "            \n",
    "#             # Display new plots\n",
    "#             plot_img(data)\n",
    "#     else:\n",
    "#         print(f\"No outlier found for Patient ID: {selected_patient_id}\")\n",
    "\n",
    "# plot_button.on_click(on_plot_button_clicked)\n",
    "\n",
    "# plot_boxplots_with_outliers(df_test, outliers_df)\n",
    "# display(diff_selector, outlier_selector, plot_button, output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import itk\n",
    "# Initialize UI elements\n",
    "diff_selector = widgets.Dropdown(options=['0_dist', '1_dist', '2_dist', 'euclidean_dist'], description='Mode:')\n",
    "outlier_selector = widgets.Dropdown(description='Outlier:')\n",
    "plot_button = widgets.Button(description='Compare',\n",
    "                             layout=widgets.Layout(width='200px', height='50px', margin='20px 10px 10px 400px'),\n",
    "                             style={'button_color': 'lightblue'})\n",
    "\n",
    "# Text areas to display the coordinates\n",
    "true_coords_text = widgets.Textarea(value=\"\", description=\"True Coord:\", layout=widgets.Layout(width='350px', height='55px'))\n",
    "pred_coords_text = widgets.Textarea(value=\"\", description=\"Pred Coord:\", layout=widgets.Layout(width='350px', height='55px'))\n",
    "\n",
    "def update_outliers(*args):\n",
    "    diff_mode = diff_selector.value\n",
    "    # Filter the outliers_df based on the selected mode\n",
    "    outliers_filtered = outliers_df[outliers_df['type'] == diff_mode]\n",
    "    # Create unique identifiers for each outlier\n",
    "    # outlier_options = [f\"{row['PatientID']}_{extract_name(row['moving'])}\" for _, row in outliers_filtered.iterrows()]\n",
    "    \n",
    "    outlier_selector.options = outliers_df['PatientID']\n",
    "\n",
    "# Call the update function initially to set default values\n",
    "update_outliers()\n",
    "\n",
    "# Observe changes in the diff_selector to update outlier_selector\n",
    "diff_selector.observe(update_outliers, 'value')\n",
    "\n",
    "def on_plot_button_clicked(b):\n",
    "    selected_option = outlier_selector.value\n",
    "    if selected_option:\n",
    "        # Extract PatientID and the unique identifier from the selected option\n",
    "        # patient_id, iter_rctp = selected_option.split('_', 1)\n",
    "        # print(patient_id, iter_rctp)\n",
    "        # Debugging: Print the selected option details\n",
    "        # print(f\"Selected option: PatientID={patient_id}, Iter_rCTp={iter_rctp}\")\n",
    "\n",
    "        # Filter the outliers dataframe to find the matching row\n",
    "        selected_outlier = outliers_df[\n",
    "            (outliers_df['PatientID'] == selected_option)\n",
    "        ]\n",
    "        \n",
    "        # Debugging: Check the result of the filtering\n",
    "        # print(f\"Filtered outlier dataframe:\\n{selected_outlier}\")\n",
    "\n",
    "        if not selected_outlier.empty:\n",
    "            outlier = selected_outlier.iloc[0].to_dict()\n",
    "            \n",
    "            # Display the coordinates\n",
    "            true_coords = (outlier['true_0'], outlier['true_1'], outlier['true_2'])\n",
    "            pred_coords = (outlier['pred_0'], outlier['pred_1'], outlier['pred_2'])\n",
    "            true_coords_text.value = f\"{true_coords}\"\n",
    "            pred_coords_text.value = f\"{pred_coords}\"\n",
    "            \n",
    "            data = making_array(outlier)\n",
    "            with output:\n",
    "                clear_output(wait=True)\n",
    "                plot_img(data)\n",
    "        else:\n",
    "            print(f\"No outlier found for Patient ID: {selected_option}\")\n",
    "\n",
    "\n",
    "\n",
    "plot_button.on_click(on_plot_button_clicked)\n",
    "\n",
    "# Output widget for plots\n",
    "output = widgets.Output()\n",
    "boxplot_output = widgets.Output()\n",
    "\n",
    "# Create layout for mode and outlier dropdowns\n",
    "dropdowns_layout = widgets.VBox([diff_selector, outlier_selector])\n",
    "\n",
    "# Create layout for dropdowns and text areas\n",
    "controls_layout = widgets.HBox([dropdowns_layout, true_coords_text, pred_coords_text])\n",
    "\n",
    "# # Display the box plot in a separate output area\n",
    "# with boxplot_output:\n",
    "#     plot_boxplots_with_outliers(df_test, outliers_df)\n",
    "\n",
    "# Display the dashboard with the box plot at the top\n",
    "display(boxplot_output, controls_layout, plot_button, output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming df_test contains the calculated differences and Euclidean distance for each row\n",
    "\n",
    "# Preparing the data for the violin plot\n",
    "# The data structure needed for seaborn violinplot is different, so we need to melt the DataFrame\n",
    "\n",
    "# Create a new DataFrame suitable for seaborn's violinplot\n",
    "melted_df = df_test.melt(value_vars=['diff_0', 'diff_1', 'diff_2', 'euclidean_dist'], \n",
    "                         var_name='Difference_Type', value_name='Value')\n",
    "\n",
    "# Plotting the violin plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.violinplot(x='Difference_Type', y='Value', data=melted_df)\n",
    "plt.title('Violin Plot of Differences and Euclidean Distances')\n",
    "plt.ylabel('Values')\n",
    "plt.xlabel('Difference Type')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Example data: Replace with your actual CT pair names and their corresponding errors\n",
    "ct_pairs = ['CT_Pair_{}'.format(i) for i in range(1, 21)]\n",
    "errors = [2.5, 1.2, 3.7, 0.9, 4.1, 2.8, 1.0, 3.3, 1.5, 0.7, 2.1, 4.5, 3.9, 0.5, 1.7, 2.4, 0.8, 3.1, 2.2, 1.3]\n",
    "\n",
    "# Create a dictionary for the word cloud\n",
    "error_dict = {ct_pairs[i]: errors[i] for i in range(len(ct_pairs))}\n",
    "\n",
    "# Generate word cloud\n",
    "wordcloud = WordCloud(width=800, height=400, background_color='white').generate_from_frequencies(error_dict)\n",
    "\n",
    "# Create a matrix of errors for the heatmap\n",
    "# Here, we'll simulate a 5x4 matrix for demonstration purposes\n",
    "error_matrix = np.array(errors).reshape(5, 4)\n",
    "\n",
    "# Generate heatmap\n",
    "plt.figure(figsize=(15, 8))\n",
    "\n",
    "# First plot the heatmap\n",
    "ax = sns.heatmap(error_matrix, annot=True, cmap='coolwarm', cbar=True, xticklabels=False, yticklabels=False)\n",
    "\n",
    "# Overlay the word cloud\n",
    "plt.imshow(wordcloud.to_array(), aspect=ax.get_aspect(), extent=ax.get_xlim() + ax.get_ylim(), zorder=1, alpha=0.5)\n",
    "\n",
    "plt.title(\"Combined Word Cloud and Heatmap of Prediction Errors for CT Pairs\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------\n",
    "# Seaching for all forders:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Folder</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>test_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20240821_182303_505_Dual_DCNN_LReLu_4_2_tr_7.5...</td>\n",
       "      <td>7.532</td>\n",
       "      <td>7.842</td>\n",
       "      <td>7.448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20240827_175450_205_Dual_DCNN_LReLu_2_251_tr_0...</td>\n",
       "      <td>0.973</td>\n",
       "      <td>1.552</td>\n",
       "      <td>3.041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20240908_195955_10_Dual_DCNN_LReLu_4_211_tr_5....</td>\n",
       "      <td>5.197</td>\n",
       "      <td>7.092</td>\n",
       "      <td>7.041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20240828_172154_341_Dual_DCNN_LReLu_0_216_tr_1...</td>\n",
       "      <td>1.596</td>\n",
       "      <td>4.077</td>\n",
       "      <td>5.038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20240821_202547_341_Dual_DCNN_LReLu_0_191_tr_1...</td>\n",
       "      <td>1.434</td>\n",
       "      <td>4.633</td>\n",
       "      <td>5.738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>20240906_171602_8_Dual_DCNN_LReLu_0_270_tr_1.8...</td>\n",
       "      <td>1.834</td>\n",
       "      <td>4.141</td>\n",
       "      <td>4.213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>20240824_150329_341_Dual_DCNN_LReLu_0_58_tr_1....</td>\n",
       "      <td>1.712</td>\n",
       "      <td>3.650</td>\n",
       "      <td>3.303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>20240906_182243_8_Dual_DCNN_LReLu_3_141_tr_0.7...</td>\n",
       "      <td>0.709</td>\n",
       "      <td>3.174</td>\n",
       "      <td>4.768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>20240821_222342_505_Dual_DCNN_LReLu_4_225_tr_1...</td>\n",
       "      <td>1.308</td>\n",
       "      <td>3.914</td>\n",
       "      <td>5.300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>20240822_170416_205_Dual_DCNN_LReLu_2_175_tr_1...</td>\n",
       "      <td>1.024</td>\n",
       "      <td>1.930</td>\n",
       "      <td>2.972</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Folder  train_loss  val_loss  \\\n",
       "1    20240821_182303_505_Dual_DCNN_LReLu_4_2_tr_7.5...       7.532     7.842   \n",
       "5    20240827_175450_205_Dual_DCNN_LReLu_2_251_tr_0...       0.973     1.552   \n",
       "6    20240908_195955_10_Dual_DCNN_LReLu_4_211_tr_5....       5.197     7.092   \n",
       "7    20240828_172154_341_Dual_DCNN_LReLu_0_216_tr_1...       1.596     4.077   \n",
       "8    20240821_202547_341_Dual_DCNN_LReLu_0_191_tr_1...       1.434     4.633   \n",
       "..                                                 ...         ...       ...   \n",
       "99   20240906_171602_8_Dual_DCNN_LReLu_0_270_tr_1.8...       1.834     4.141   \n",
       "101  20240824_150329_341_Dual_DCNN_LReLu_0_58_tr_1....       1.712     3.650   \n",
       "102  20240906_182243_8_Dual_DCNN_LReLu_3_141_tr_0.7...       0.709     3.174   \n",
       "103  20240821_222342_505_Dual_DCNN_LReLu_4_225_tr_1...       1.308     3.914   \n",
       "104  20240822_170416_205_Dual_DCNN_LReLu_2_175_tr_1...       1.024     1.930   \n",
       "\n",
       "     test_loss  \n",
       "1        7.448  \n",
       "5        3.041  \n",
       "6        7.041  \n",
       "7        5.038  \n",
       "8        5.738  \n",
       "..         ...  \n",
       "99       4.213  \n",
       "101      3.303  \n",
       "102      4.768  \n",
       "103      5.300  \n",
       "104      2.972  \n",
       "\n",
       "[70 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# Define the main root directory\n",
    "main_root = '/data/bahrdoh/Deep_Learning_Pipeline_Test/experiments_dose/test'\n",
    "# main_root = '/data/bahrdoh/Deep_Learning_Pipeline_Dose/experiments_dose/test'\n",
    "# '/data/bahrdoh/Deep_Learning_Pipeline/experiments/test'\n",
    "\n",
    "# Function to extract values from folder names\n",
    "def extract_losses(folder_name):\n",
    "    match = re.search(r'tr_(\\d+\\.\\d+)_val_(\\d+\\.\\d+)_test_(\\d+\\.\\d+)(?:_avg_tr_(\\d+\\.\\d+)_val_(\\d+\\.\\d+)_test_(\\d+\\.\\d+))?', folder_name)\n",
    "    if match:\n",
    "        train_loss = float(match.group(1))\n",
    "        val_loss = float(match.group(2))\n",
    "        test_loss = float(match.group(3))\n",
    "        avg_train_loss = float(match.group(4)) if match.group(4) else None\n",
    "        avg_val_loss = float(match.group(5)) if match.group(5) else None\n",
    "        avg_test_loss = float(match.group(6)) if match.group(6) else None\n",
    "        return train_loss, val_loss, test_loss, avg_train_loss, avg_val_loss, avg_test_loss\n",
    "    else:\n",
    "        return None, None, None, None, None, None\n",
    "\n",
    "# List all directories in the main root\n",
    "folders = [f for f in os.listdir(main_root) if os.path.isdir(os.path.join(main_root, f))]\n",
    "\n",
    "# Iterate over the folders and extract losses\n",
    "losses_data = []\n",
    "for folder in folders:\n",
    "    train_loss, val_loss, test_loss, avg_train_loss, avg_val_loss, avg_test_loss = extract_losses(folder)\n",
    "    losses_data.append({\n",
    "        'Folder': folder,\n",
    "        'train_loss': train_loss,\n",
    "        'val_loss': val_loss,\n",
    "        'test_loss': test_loss\n",
    "        # 'mean_train_loss': avg_train_loss,\n",
    "        # 'mean_val_loss': avg_val_loss,\n",
    "        # 'mean_test_loss': avg_test_loss\n",
    "    })\n",
    "\n",
    "\n",
    "# Create a DataFrame from the extracted data\n",
    "df_losses = pd.DataFrame(losses_data)\n",
    "df_losses = df_losses.dropna()\n",
    "# Display the DataFrame\n",
    "df_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Folder        0\n",
       "train_loss    0\n",
       "val_loss      0\n",
       "test_loss     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_values = df_losses.isnull()\n",
    "df_losses.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Folder</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>test_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20240821_182303_505_Dual_DCNN_LReLu_4_2_tr_7.5...</td>\n",
       "      <td>7.532</td>\n",
       "      <td>7.842</td>\n",
       "      <td>7.448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20240827_175450_205_Dual_DCNN_LReLu_2_251_tr_0...</td>\n",
       "      <td>0.973</td>\n",
       "      <td>1.552</td>\n",
       "      <td>3.041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20240908_195955_10_Dual_DCNN_LReLu_4_211_tr_5....</td>\n",
       "      <td>5.197</td>\n",
       "      <td>7.092</td>\n",
       "      <td>7.041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20240828_172154_341_Dual_DCNN_LReLu_0_216_tr_1...</td>\n",
       "      <td>1.596</td>\n",
       "      <td>4.077</td>\n",
       "      <td>5.038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20240821_202547_341_Dual_DCNN_LReLu_0_191_tr_1...</td>\n",
       "      <td>1.434</td>\n",
       "      <td>4.633</td>\n",
       "      <td>5.738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>20240906_171602_8_Dual_DCNN_LReLu_0_270_tr_1.8...</td>\n",
       "      <td>1.834</td>\n",
       "      <td>4.141</td>\n",
       "      <td>4.213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>20240824_150329_341_Dual_DCNN_LReLu_0_58_tr_1....</td>\n",
       "      <td>1.712</td>\n",
       "      <td>3.650</td>\n",
       "      <td>3.303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>20240906_182243_8_Dual_DCNN_LReLu_3_141_tr_0.7...</td>\n",
       "      <td>0.709</td>\n",
       "      <td>3.174</td>\n",
       "      <td>4.768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>20240821_222342_505_Dual_DCNN_LReLu_4_225_tr_1...</td>\n",
       "      <td>1.308</td>\n",
       "      <td>3.914</td>\n",
       "      <td>5.300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>20240822_170416_205_Dual_DCNN_LReLu_2_175_tr_1...</td>\n",
       "      <td>1.024</td>\n",
       "      <td>1.930</td>\n",
       "      <td>2.972</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Folder  train_loss  val_loss  \\\n",
       "1    20240821_182303_505_Dual_DCNN_LReLu_4_2_tr_7.5...       7.532     7.842   \n",
       "5    20240827_175450_205_Dual_DCNN_LReLu_2_251_tr_0...       0.973     1.552   \n",
       "6    20240908_195955_10_Dual_DCNN_LReLu_4_211_tr_5....       5.197     7.092   \n",
       "7    20240828_172154_341_Dual_DCNN_LReLu_0_216_tr_1...       1.596     4.077   \n",
       "8    20240821_202547_341_Dual_DCNN_LReLu_0_191_tr_1...       1.434     4.633   \n",
       "..                                                 ...         ...       ...   \n",
       "99   20240906_171602_8_Dual_DCNN_LReLu_0_270_tr_1.8...       1.834     4.141   \n",
       "101  20240824_150329_341_Dual_DCNN_LReLu_0_58_tr_1....       1.712     3.650   \n",
       "102  20240906_182243_8_Dual_DCNN_LReLu_3_141_tr_0.7...       0.709     3.174   \n",
       "103  20240821_222342_505_Dual_DCNN_LReLu_4_225_tr_1...       1.308     3.914   \n",
       "104  20240822_170416_205_Dual_DCNN_LReLu_2_175_tr_1...       1.024     1.930   \n",
       "\n",
       "     test_loss  \n",
       "1        7.448  \n",
       "5        3.041  \n",
       "6        7.041  \n",
       "7        5.038  \n",
       "8        5.738  \n",
       "..         ...  \n",
       "99       4.213  \n",
       "101      3.303  \n",
       "102      4.768  \n",
       "103      5.300  \n",
       "104      2.972  \n",
       "\n",
       "[70 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Folder</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>20240902_115416_120_Dual_DCNN_LReLu_9_296_tr_0...</td>\n",
       "      <td>0.912</td>\n",
       "      <td>1.176</td>\n",
       "      <td>3.210</td>\n",
       "      <td>Lowest Validation Loss: [0.912, 1.176, 3.21]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>20240831_040942_838_Dual_DCNN_LReLu_3_185_tr_0...</td>\n",
       "      <td>0.962</td>\n",
       "      <td>1.384</td>\n",
       "      <td>2.519</td>\n",
       "      <td>Lowest Test Loss: [0.962, 1.384, 2.519]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>20240906_182243_8_Dual_DCNN_LReLu_3_141_tr_0.7...</td>\n",
       "      <td>0.709</td>\n",
       "      <td>3.174</td>\n",
       "      <td>4.768</td>\n",
       "      <td>Lowest Train Loss: [0.709, 3.174, 4.768]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Folder  train_loss  val_loss  \\\n",
       "25   20240902_115416_120_Dual_DCNN_LReLu_9_296_tr_0...       0.912     1.176   \n",
       "48   20240831_040942_838_Dual_DCNN_LReLu_3_185_tr_0...       0.962     1.384   \n",
       "102  20240906_182243_8_Dual_DCNN_LReLu_3_141_tr_0.7...       0.709     3.174   \n",
       "\n",
       "     test_loss                                           tag  \n",
       "25       3.210  Lowest Validation Loss: [0.912, 1.176, 3.21]  \n",
       "48       2.519       Lowest Test Loss: [0.962, 1.384, 2.519]  \n",
       "102      4.768      Lowest Train Loss: [0.709, 3.174, 4.768]  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensure to drop rows with any NaN values\n",
    "df_losses = df_losses.dropna(subset=['train_loss', 'val_loss', 'test_loss'])\n",
    "\n",
    "# Default tag for all rows\n",
    "df_losses['tag'] = 'Other'\n",
    "\n",
    "# Tagging the row with the lowest train loss\n",
    "lowest_train_idx = df_losses['train_loss'].idxmin()\n",
    "df_losses.loc[lowest_train_idx, 'tag'] = (\n",
    "    f\"Lowest Train Loss: [{df_losses.loc[lowest_train_idx, 'train_loss']}, \"\n",
    "    f\"{df_losses.loc[lowest_train_idx, 'val_loss']}, \"\n",
    "    f\"{df_losses.loc[lowest_train_idx, 'test_loss']}]\"\n",
    ")\n",
    "\n",
    "# Tagging the row with the lowest validation loss\n",
    "lowest_val_idx = df_losses['val_loss'].idxmin()\n",
    "df_losses.loc[lowest_val_idx, 'tag'] = (\n",
    "    f\"Lowest Validation Loss: [{df_losses.loc[lowest_val_idx, 'train_loss']}, \"\n",
    "    f\"{df_losses.loc[lowest_val_idx, 'val_loss']}, \"\n",
    "    f\"{df_losses.loc[lowest_val_idx, 'test_loss']}]\"\n",
    ")\n",
    "\n",
    "# Tagging the row with the lowest test loss\n",
    "lowest_test_idx = df_losses['test_loss'].idxmin()\n",
    "df_losses.loc[lowest_test_idx, 'tag'] = (\n",
    "    f\"Lowest Test Loss: [{df_losses.loc[lowest_test_idx, 'train_loss']}, \"\n",
    "    f\"{df_losses.loc[lowest_test_idx, 'val_loss']}, \"\n",
    "    f\"{df_losses.loc[lowest_test_idx, 'test_loss']}]\"\n",
    ")\n",
    "\n",
    "# If you need to tag based on mean losses, uncomment and use similar logic:\n",
    "# lowest_mean_train_idx = df_losses['mean_train_loss'].idxmin()\n",
    "# lowest_mean_val_idx = df_losses['mean_val_loss'].idxmin()\n",
    "# lowest_mean_test_idx = df_losses['mean_test_loss'].idxmin()\n",
    "\n",
    "# if 'mean_train_loss' in df_losses.columns:\n",
    "#     df_losses.loc[lowest_mean_train_idx, 'tag'] = (\n",
    "#         f\"Lowest Mean Train Loss: [{df_losses.loc[lowest_mean_train_idx, 'mean_train_loss']}, \"\n",
    "#         f\"{df_losses.loc[lowest_mean_train_idx, 'mean_val_loss']}, \"\n",
    "#         f\"{df_losses.loc[lowest_mean_train_idx, 'mean_test_loss']}]\"\n",
    "#     )\n",
    "\n",
    "# if 'mean_val_loss' in df_losses.columns:\n",
    "#     df_losses.loc[lowest_mean_val_idx, 'tag'] = (\n",
    "#         f\"Lowest Mean Validation Loss: [{df_losses.loc[lowest_mean_val_idx, 'mean_train_loss']}, \"\n",
    "#         f\"{df_losses.loc[lowest_mean_val_idx, 'mean_val_loss']}, \"\n",
    "#         f\"{df_losses.loc[lowest_mean_val_idx, 'mean_test_loss']}]\"\n",
    "#     )\n",
    "\n",
    "# if 'mean_test_loss' in df_losses.columns:\n",
    "#     df_losses.loc[lowest_mean_test_idx, 'tag'] = (\n",
    "#         f\"Lowest Mean Test Loss: [{df_losses.loc[lowest_mean_test_idx, 'mean_train_loss']}, \"\n",
    "#         f\"{df_losses.loc[lowest_mean_test_idx, 'mean_val_loss']}, \"\n",
    "#         f\"{df_losses.loc[lowest_mean_test_idx, 'mean_test_loss']}]\"\n",
    "#     )\n",
    "\n",
    "# Filtering out the tagged rows\n",
    "df_filtered_tagged_losses = df_losses[df_losses['tag'] != 'Other']\n",
    "\n",
    "# Display the updated DataFrame with tags\n",
    "df_filtered_tagged_losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Lowest Validation Loss: [0.912, 1.176, 3.21]', 'Lowest Test Loss: [0.962, 1.384, 2.519]', 'Lowest Train Loss: [0.709, 3.174, 4.768]']\n"
     ]
    }
   ],
   "source": [
    "# Saving the DataFrame as a pickle file\n",
    "pickle_file_path = \"selected_folders_3.pkl\"\n",
    "df_filtered_tagged_losses.to_pickle(pickle_file_path)\n",
    "\n",
    "# Loading the DataFrame from the pickle file\n",
    "df_loaded = pd.read_pickle(pickle_file_path)\n",
    "\n",
    "print(df_loaded['tag'].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming df_filtered_tagged_losses is your DataFrame\n",
    "# Replace the following line with the actual loading of your DataFrame if necessary\n",
    "# df_filtered_tagged_losses = pd.read_pickle('selected_folders_2.pkl')\n",
    "\n",
    "# Folder name to search for\n",
    "folder_name_to_search = '20240722_191053_410_Dual_DCNN_LReLu_1_149_tr_0.988_val_3.565_test_3.683_avg_tr_1.018_val_4.223_test_4.064'\n",
    "\n",
    "# Check if the folder name exists in the Folder column\n",
    "folder_exists = folder_name_to_search in df_loaded['Folder'].values\n",
    "\n",
    "if folder_exists:\n",
    "    print(f\"The folder '{folder_name_to_search}' exists in the DataFrame.\")\n",
    "else:\n",
    "    print(f\"The folder '{folder_name_to_search}' does not exist in the DataFrame.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
