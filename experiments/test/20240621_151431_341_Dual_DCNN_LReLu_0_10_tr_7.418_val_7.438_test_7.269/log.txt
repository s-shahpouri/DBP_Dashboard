2024-06-21 14:24:55,814 - INFO: Device: cuda.
2024-06-21 14:24:55,814 - INFO: Torch version: 2.0.1+cu117.
2024-06-21 14:24:55,814 - INFO: Torch.backends.cudnn.benchmark: True.
2024-06-21 14:24:55,814 - INFO: Model name: Dual_DCNN_LReLu
2024-06-21 14:24:55,814 - INFO: Seed: 4
2024-06-21 14:24:55,815 - INFO: 42 patients have been found in the data directory.
2024-06-21 14:24:55,853 - INFO: Train set contains 32 patients.
2024-06-21 14:24:55,853 - INFO: Val set contains 5 patients.
2024-06-21 14:24:55,853 - INFO: Test set contains 5 patients.
2024-06-21 14:24:55,853 - INFO: Fold: 0
2024-06-21 14:24:55,854 - INFO: Performing 2-fold Cross Validation.
2024-06-21 14:24:55,854 - INFO: Train Set: 910/1970, percent: 0.462
2024-06-21 14:24:55,854 - INFO: Val Set: 910/1970, percent: 0.462
2024-06-21 14:24:55,855 - INFO: Test Set: 150/1970, percent: 0.076
2024-06-21 14:24:55,984 - INFO: To_device: False.
2024-06-21 14:24:55,985 - INFO: Transformers have been made successfully.
2024-06-21 14:24:55,985 - INFO: Dataset type: cache.
2024-06-21 14:24:55,985 - INFO: Dataloader type: standard.
2024-06-21 14:26:46,690 - INFO: Train dataloader arguments.
2024-06-21 14:26:46,690 - INFO: 	Batch_size: 32.
2024-06-21 14:26:46,690 - INFO: 	Shuffle: True.
2024-06-21 14:26:46,690 - INFO: 	Sampler: None.
2024-06-21 14:26:46,690 - INFO: 	Num_workers: 4.
2024-06-21 14:26:46,690 - INFO: 	Drop_last: False.
2024-06-21 14:26:46,738 - INFO: Dual_DCNN_LReLU(
  (conv_blocks_fixed): ModuleList(
    (0): conv_block_two(
      (pad1): conv3d_padding_same()
      (conv1): Conv3d(1, 8, kernel_size=(1, 6, 6), stride=(2, 2, 2))
      (norm1): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activation1): LeakyReLU(negative_slope=0.1)
      (pad2): conv3d_padding_same()
      (conv2): Conv3d(8, 8, kernel_size=(1, 6, 6), stride=(1, 1, 1))
      (norm2): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activation2): LeakyReLU(negative_slope=0.1)
      (max_pooling): MaxPool3d(kernel_size=3, stride=1, padding=0, dilation=1, ceil_mode=False)
    )
    (1): conv_block_two(
      (pad1): conv3d_padding_same()
      (conv1): Conv3d(8, 8, kernel_size=(1, 3, 3), stride=(2, 2, 2))
      (norm1): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activation1): LeakyReLU(negative_slope=0.1)
      (pad2): conv3d_padding_same()
      (conv2): Conv3d(8, 8, kernel_size=(1, 3, 3), stride=(1, 1, 1))
      (norm2): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activation2): LeakyReLU(negative_slope=0.1)
      (max_pooling): MaxPool3d(kernel_size=3, stride=1, padding=0, dilation=1, ceil_mode=False)
    )
    (2): conv_block_two(
      (pad1): conv3d_padding_same()
      (conv1): Conv3d(8, 16, kernel_size=(1, 3, 3), stride=(2, 2, 2))
      (norm1): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activation1): LeakyReLU(negative_slope=0.1)
      (pad2): conv3d_padding_same()
      (conv2): Conv3d(16, 16, kernel_size=(1, 3, 3), stride=(1, 1, 1))
      (norm2): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activation2): LeakyReLU(negative_slope=0.1)
      (max_pooling): MaxPool3d(kernel_size=3, stride=1, padding=0, dilation=1, ceil_mode=False)
    )
    (3): conv_block_two(
      (pad1): conv3d_padding_same()
      (conv1): Conv3d(16, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1))
      (norm1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activation1): LeakyReLU(negative_slope=0.1)
      (pad2): conv3d_padding_same()
      (conv2): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1))
      (norm2): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activation2): LeakyReLU(negative_slope=0.1)
      (max_pooling): MaxPool3d(kernel_size=3, stride=1, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (conv_blocks_moving): ModuleList(
    (0): conv_block_two(
      (pad1): conv3d_padding_same()
      (conv1): Conv3d(1, 8, kernel_size=(1, 6, 6), stride=(2, 2, 2))
      (norm1): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activation1): LeakyReLU(negative_slope=0.1)
      (pad2): conv3d_padding_same()
      (conv2): Conv3d(8, 8, kernel_size=(1, 6, 6), stride=(1, 1, 1))
      (norm2): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activation2): LeakyReLU(negative_slope=0.1)
      (max_pooling): MaxPool3d(kernel_size=3, stride=1, padding=0, dilation=1, ceil_mode=False)
    )
    (1): conv_block_two(
      (pad1): conv3d_padding_same()
      (conv1): Conv3d(8, 8, kernel_size=(1, 3, 3), stride=(2, 2, 2))
      (norm1): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activation1): LeakyReLU(negative_slope=0.1)
      (pad2): conv3d_padding_same()
      (conv2): Conv3d(8, 8, kernel_size=(1, 3, 3), stride=(1, 1, 1))
      (norm2): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activation2): LeakyReLU(negative_slope=0.1)
      (max_pooling): MaxPool3d(kernel_size=3, stride=1, padding=0, dilation=1, ceil_mode=False)
    )
    (2): conv_block_two(
      (pad1): conv3d_padding_same()
      (conv1): Conv3d(8, 16, kernel_size=(1, 3, 3), stride=(2, 2, 2))
      (norm1): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activation1): LeakyReLU(negative_slope=0.1)
      (pad2): conv3d_padding_same()
      (conv2): Conv3d(16, 16, kernel_size=(1, 3, 3), stride=(1, 1, 1))
      (norm2): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activation2): LeakyReLU(negative_slope=0.1)
      (max_pooling): MaxPool3d(kernel_size=3, stride=1, padding=0, dilation=1, ceil_mode=False)
    )
    (3): conv_block_two(
      (pad1): conv3d_padding_same()
      (conv1): Conv3d(16, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1))
      (norm1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activation1): LeakyReLU(negative_slope=0.1)
      (pad2): conv3d_padding_same()
      (conv2): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1))
      (norm2): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activation2): LeakyReLU(negative_slope=0.1)
      (max_pooling): MaxPool3d(kernel_size=3, stride=1, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (linear_layers): ModuleList(
    (0): Dropout(p=0.35973448489278154, inplace=False)
    (1): Linear(in_features=262144, out_features=32, bias=True)
  )
  (out_layer): Output(
    in_features=32, out_features=3, bias=True
    (fc): Linear(in_features=32, out_features=3, bias=True)
  )
)
2024-06-21 14:26:47,594 - INFO: Weight init name: kaiming_uniform.
2024-06-21 14:26:50,009 - INFO: Number of training iterations per epoch: 29.
2024-06-21 14:26:50,009 - INFO: Epoch 1/10...
2024-06-21 14:26:50,010 - INFO: Learning rate: 4.6201611404555185e-05.
2024-06-21 14:26:50,010 - INFO: Batch size: 32.
2024-06-21 14:26:50,010 - INFO: Dataset:
2024-06-21 14:26:50,010 - INFO: Batch size:
2024-06-21 14:26:50,010 - INFO: Number of workers:
2024-06-21 14:26:52,950 - INFO: Epoch: 1/10, Batch: 1/29, Batch_Loss_Train: 7.229
2024-06-21 14:26:53,255 - INFO: Epoch: 1/10, Batch: 2/29, Batch_Loss_Train: 7.805
2024-06-21 14:26:53,648 - INFO: Epoch: 1/10, Batch: 3/29, Batch_Loss_Train: 6.995
2024-06-21 14:26:53,954 - INFO: Epoch: 1/10, Batch: 4/29, Batch_Loss_Train: 6.998
2024-06-21 14:26:54,351 - INFO: Epoch: 1/10, Batch: 5/29, Batch_Loss_Train: 7.297
2024-06-21 14:26:54,678 - INFO: Epoch: 1/10, Batch: 6/29, Batch_Loss_Train: 6.870
2024-06-21 14:26:55,064 - INFO: Epoch: 1/10, Batch: 7/29, Batch_Loss_Train: 7.797
2024-06-21 14:26:55,379 - INFO: Epoch: 1/10, Batch: 8/29, Batch_Loss_Train: 7.839
2024-06-21 14:26:55,768 - INFO: Epoch: 1/10, Batch: 9/29, Batch_Loss_Train: 7.181
2024-06-21 14:26:56,088 - INFO: Epoch: 1/10, Batch: 10/29, Batch_Loss_Train: 6.813
2024-06-21 14:26:56,468 - INFO: Epoch: 1/10, Batch: 11/29, Batch_Loss_Train: 7.933
2024-06-21 14:26:56,785 - INFO: Epoch: 1/10, Batch: 12/29, Batch_Loss_Train: 6.677
2024-06-21 14:26:57,189 - INFO: Epoch: 1/10, Batch: 13/29, Batch_Loss_Train: 7.535
2024-06-21 14:26:57,524 - INFO: Epoch: 1/10, Batch: 14/29, Batch_Loss_Train: 6.758
2024-06-21 14:26:57,917 - INFO: Epoch: 1/10, Batch: 15/29, Batch_Loss_Train: 7.531
2024-06-21 14:26:58,232 - INFO: Epoch: 1/10, Batch: 16/29, Batch_Loss_Train: 7.008
2024-06-21 14:26:58,632 - INFO: Epoch: 1/10, Batch: 17/29, Batch_Loss_Train: 6.538
2024-06-21 14:26:58,958 - INFO: Epoch: 1/10, Batch: 18/29, Batch_Loss_Train: 6.452
2024-06-21 14:26:59,342 - INFO: Epoch: 1/10, Batch: 19/29, Batch_Loss_Train: 7.529
2024-06-21 14:26:59,651 - INFO: Epoch: 1/10, Batch: 20/29, Batch_Loss_Train: 6.744
2024-06-21 14:27:00,044 - INFO: Epoch: 1/10, Batch: 21/29, Batch_Loss_Train: 7.364
2024-06-21 14:27:00,371 - INFO: Epoch: 1/10, Batch: 22/29, Batch_Loss_Train: 7.491
2024-06-21 14:27:00,743 - INFO: Epoch: 1/10, Batch: 23/29, Batch_Loss_Train: 7.094
2024-06-21 14:27:01,057 - INFO: Epoch: 1/10, Batch: 24/29, Batch_Loss_Train: 6.715
2024-06-21 14:27:01,441 - INFO: Epoch: 1/10, Batch: 25/29, Batch_Loss_Train: 6.294
2024-06-21 14:27:01,763 - INFO: Epoch: 1/10, Batch: 26/29, Batch_Loss_Train: 7.066
2024-06-21 14:27:02,133 - INFO: Epoch: 1/10, Batch: 27/29, Batch_Loss_Train: 6.666
2024-06-21 14:27:02,443 - INFO: Epoch: 1/10, Batch: 28/29, Batch_Loss_Train: 7.287
2024-06-21 14:27:03,719 - INFO: Epoch: 1/10, Batch: 29/29, Batch_Loss_Train: 5.979
2024-06-21 14:27:14,695 - INFO: 1/10 final results:
2024-06-21 14:27:14,695 - INFO: Training loss: 7.086.
2024-06-21 14:27:14,695 - INFO: Training MAE: 7.108.
2024-06-21 14:27:14,695 - INFO: Training MSE: 68.464.
2024-06-21 14:27:35,112 - INFO: Epoch: 1/10, Loss_train: 7.085699311618147, Loss_val: 7.207277051333723
2024-06-21 14:27:35,112 - INFO: Best internal validation val_loss: inf at epoch: 0.
2024-06-21 14:27:35,112 - INFO: Epoch 2/10...
2024-06-21 14:27:35,112 - INFO: Learning rate: 4.6201611404555185e-05.
2024-06-21 14:27:35,112 - INFO: Batch size: 32.
2024-06-21 14:27:35,115 - INFO: Dataset:
2024-06-21 14:27:35,115 - INFO: Batch size:
2024-06-21 14:27:35,115 - INFO: Number of workers:
2024-06-21 14:27:36,254 - INFO: Epoch: 2/10, Batch: 1/29, Batch_Loss_Train: 6.015
2024-06-21 14:27:36,576 - INFO: Epoch: 2/10, Batch: 2/29, Batch_Loss_Train: 6.341
2024-06-21 14:27:36,983 - INFO: Epoch: 2/10, Batch: 3/29, Batch_Loss_Train: 5.361
2024-06-21 14:27:37,303 - INFO: Epoch: 2/10, Batch: 4/29, Batch_Loss_Train: 5.782
2024-06-21 14:27:37,714 - INFO: Epoch: 2/10, Batch: 5/29, Batch_Loss_Train: 5.049
2024-06-21 14:27:38,017 - INFO: Epoch: 2/10, Batch: 6/29, Batch_Loss_Train: 6.226
2024-06-21 14:27:38,417 - INFO: Epoch: 2/10, Batch: 7/29, Batch_Loss_Train: 6.000
2024-06-21 14:27:38,733 - INFO: Epoch: 2/10, Batch: 8/29, Batch_Loss_Train: 5.948
2024-06-21 14:27:39,143 - INFO: Epoch: 2/10, Batch: 9/29, Batch_Loss_Train: 6.774
2024-06-21 14:27:39,441 - INFO: Epoch: 2/10, Batch: 10/29, Batch_Loss_Train: 5.402
2024-06-21 14:27:39,834 - INFO: Epoch: 2/10, Batch: 11/29, Batch_Loss_Train: 5.442
2024-06-21 14:27:40,151 - INFO: Epoch: 2/10, Batch: 12/29, Batch_Loss_Train: 6.528
2024-06-21 14:27:40,568 - INFO: Epoch: 2/10, Batch: 13/29, Batch_Loss_Train: 5.799
2024-06-21 14:27:40,873 - INFO: Epoch: 2/10, Batch: 14/29, Batch_Loss_Train: 4.996
2024-06-21 14:27:41,278 - INFO: Epoch: 2/10, Batch: 15/29, Batch_Loss_Train: 5.609
2024-06-21 14:27:41,592 - INFO: Epoch: 2/10, Batch: 16/29, Batch_Loss_Train: 5.756
2024-06-21 14:27:42,008 - INFO: Epoch: 2/10, Batch: 17/29, Batch_Loss_Train: 4.985
2024-06-21 14:27:42,311 - INFO: Epoch: 2/10, Batch: 18/29, Batch_Loss_Train: 5.605
2024-06-21 14:27:42,709 - INFO: Epoch: 2/10, Batch: 19/29, Batch_Loss_Train: 5.821
2024-06-21 14:27:43,019 - INFO: Epoch: 2/10, Batch: 20/29, Batch_Loss_Train: 5.355
2024-06-21 14:27:43,428 - INFO: Epoch: 2/10, Batch: 21/29, Batch_Loss_Train: 5.548
2024-06-21 14:27:43,731 - INFO: Epoch: 2/10, Batch: 22/29, Batch_Loss_Train: 5.971
2024-06-21 14:27:44,117 - INFO: Epoch: 2/10, Batch: 23/29, Batch_Loss_Train: 5.246
2024-06-21 14:27:44,431 - INFO: Epoch: 2/10, Batch: 24/29, Batch_Loss_Train: 6.184
2024-06-21 14:27:44,826 - INFO: Epoch: 2/10, Batch: 25/29, Batch_Loss_Train: 4.588
2024-06-21 14:27:45,125 - INFO: Epoch: 2/10, Batch: 26/29, Batch_Loss_Train: 5.024
2024-06-21 14:27:45,504 - INFO: Epoch: 2/10, Batch: 27/29, Batch_Loss_Train: 4.610
2024-06-21 14:27:45,815 - INFO: Epoch: 2/10, Batch: 28/29, Batch_Loss_Train: 5.399
2024-06-21 14:27:46,030 - INFO: Epoch: 2/10, Batch: 29/29, Batch_Loss_Train: 5.668
2024-06-21 14:27:56,916 - INFO: 2/10 final results:
2024-06-21 14:27:56,916 - INFO: Training loss: 5.622.
2024-06-21 14:27:56,916 - INFO: Training MAE: 5.621.
2024-06-21 14:27:56,916 - INFO: Training MSE: 46.416.
2024-06-21 14:28:17,052 - INFO: Epoch: 2/10, Loss_train: 5.6218207129116715, Loss_val: 4.903627683376444
2024-06-21 14:28:17,099 - INFO: Saved new best metric model for epoch 2.
2024-06-21 14:28:17,099 - INFO: Best internal validation val_loss: 4.904 at epoch: 2.
2024-06-21 14:28:17,099 - INFO: Epoch 3/10...
2024-06-21 14:28:17,099 - INFO: Learning rate: 4.6201611404555185e-05.
2024-06-21 14:28:17,099 - INFO: Batch size: 32.
2024-06-21 14:28:17,103 - INFO: Dataset:
2024-06-21 14:28:17,103 - INFO: Batch size:
2024-06-21 14:28:17,103 - INFO: Number of workers:
2024-06-21 14:28:18,255 - INFO: Epoch: 3/10, Batch: 1/29, Batch_Loss_Train: 5.096
2024-06-21 14:28:18,563 - INFO: Epoch: 3/10, Batch: 2/29, Batch_Loss_Train: 5.007
2024-06-21 14:28:18,954 - INFO: Epoch: 3/10, Batch: 3/29, Batch_Loss_Train: 4.447
2024-06-21 14:28:19,273 - INFO: Epoch: 3/10, Batch: 4/29, Batch_Loss_Train: 4.349
2024-06-21 14:28:19,689 - INFO: Epoch: 3/10, Batch: 5/29, Batch_Loss_Train: 4.885
2024-06-21 14:28:19,995 - INFO: Epoch: 3/10, Batch: 6/29, Batch_Loss_Train: 4.091
2024-06-21 14:28:20,385 - INFO: Epoch: 3/10, Batch: 7/29, Batch_Loss_Train: 4.472
2024-06-21 14:28:20,705 - INFO: Epoch: 3/10, Batch: 8/29, Batch_Loss_Train: 4.506
2024-06-21 14:28:21,163 - INFO: Epoch: 3/10, Batch: 9/29, Batch_Loss_Train: 4.686
2024-06-21 14:28:21,463 - INFO: Epoch: 3/10, Batch: 10/29, Batch_Loss_Train: 4.731
2024-06-21 14:28:21,845 - INFO: Epoch: 3/10, Batch: 11/29, Batch_Loss_Train: 4.342
2024-06-21 14:28:22,166 - INFO: Epoch: 3/10, Batch: 12/29, Batch_Loss_Train: 4.244
2024-06-21 14:28:22,622 - INFO: Epoch: 3/10, Batch: 13/29, Batch_Loss_Train: 4.326
2024-06-21 14:28:22,930 - INFO: Epoch: 3/10, Batch: 14/29, Batch_Loss_Train: 4.603
2024-06-21 14:28:23,332 - INFO: Epoch: 3/10, Batch: 15/29, Batch_Loss_Train: 4.937
2024-06-21 14:28:23,638 - INFO: Epoch: 3/10, Batch: 16/29, Batch_Loss_Train: 4.215
2024-06-21 14:28:24,085 - INFO: Epoch: 3/10, Batch: 17/29, Batch_Loss_Train: 3.826
2024-06-21 14:28:24,389 - INFO: Epoch: 3/10, Batch: 18/29, Batch_Loss_Train: 4.917
2024-06-21 14:28:24,769 - INFO: Epoch: 3/10, Batch: 19/29, Batch_Loss_Train: 4.015
2024-06-21 14:28:25,068 - INFO: Epoch: 3/10, Batch: 20/29, Batch_Loss_Train: 4.466
2024-06-21 14:28:25,501 - INFO: Epoch: 3/10, Batch: 21/29, Batch_Loss_Train: 4.636
2024-06-21 14:28:25,806 - INFO: Epoch: 3/10, Batch: 22/29, Batch_Loss_Train: 4.242
2024-06-21 14:28:26,192 - INFO: Epoch: 3/10, Batch: 23/29, Batch_Loss_Train: 4.137
2024-06-21 14:28:26,497 - INFO: Epoch: 3/10, Batch: 24/29, Batch_Loss_Train: 4.175
2024-06-21 14:28:26,930 - INFO: Epoch: 3/10, Batch: 25/29, Batch_Loss_Train: 4.375
2024-06-21 14:28:27,232 - INFO: Epoch: 3/10, Batch: 26/29, Batch_Loss_Train: 4.137
2024-06-21 14:28:27,615 - INFO: Epoch: 3/10, Batch: 27/29, Batch_Loss_Train: 4.312
2024-06-21 14:28:27,917 - INFO: Epoch: 3/10, Batch: 28/29, Batch_Loss_Train: 3.786
2024-06-21 14:28:28,139 - INFO: Epoch: 3/10, Batch: 29/29, Batch_Loss_Train: 5.122
2024-06-21 14:28:39,259 - INFO: 3/10 final results:
2024-06-21 14:28:39,259 - INFO: Training loss: 4.451.
2024-06-21 14:28:39,259 - INFO: Training MAE: 4.438.
2024-06-21 14:28:39,259 - INFO: Training MSE: 33.473.
2024-06-21 14:28:59,487 - INFO: Epoch: 3/10, Loss_train: 4.451175952779836, Loss_val: 4.180942551843051
2024-06-21 14:28:59,547 - INFO: Saved new best metric model for epoch 3.
2024-06-21 14:28:59,547 - INFO: Best internal validation val_loss: 4.181 at epoch: 3.
2024-06-21 14:28:59,547 - INFO: Epoch 4/10...
2024-06-21 14:28:59,547 - INFO: Learning rate: 4.6201611404555185e-05.
2024-06-21 14:28:59,547 - INFO: Batch size: 32.
2024-06-21 14:28:59,551 - INFO: Dataset:
2024-06-21 14:28:59,551 - INFO: Batch size:
2024-06-21 14:28:59,551 - INFO: Number of workers:
2024-06-21 14:29:00,694 - INFO: Epoch: 4/10, Batch: 1/29, Batch_Loss_Train: 3.727
2024-06-21 14:29:01,015 - INFO: Epoch: 4/10, Batch: 2/29, Batch_Loss_Train: 3.882
2024-06-21 14:29:01,427 - INFO: Epoch: 4/10, Batch: 3/29, Batch_Loss_Train: 3.707
2024-06-21 14:29:01,748 - INFO: Epoch: 4/10, Batch: 4/29, Batch_Loss_Train: 4.359
2024-06-21 14:29:02,159 - INFO: Epoch: 4/10, Batch: 5/29, Batch_Loss_Train: 3.607
2024-06-21 14:29:02,463 - INFO: Epoch: 4/10, Batch: 6/29, Batch_Loss_Train: 3.147
2024-06-21 14:29:02,864 - INFO: Epoch: 4/10, Batch: 7/29, Batch_Loss_Train: 4.121
2024-06-21 14:29:03,180 - INFO: Epoch: 4/10, Batch: 8/29, Batch_Loss_Train: 4.420
2024-06-21 14:29:03,592 - INFO: Epoch: 4/10, Batch: 9/29, Batch_Loss_Train: 3.867
2024-06-21 14:29:03,888 - INFO: Epoch: 4/10, Batch: 10/29, Batch_Loss_Train: 3.781
2024-06-21 14:29:04,286 - INFO: Epoch: 4/10, Batch: 11/29, Batch_Loss_Train: 3.860
2024-06-21 14:29:04,603 - INFO: Epoch: 4/10, Batch: 12/29, Batch_Loss_Train: 3.766
2024-06-21 14:29:05,023 - INFO: Epoch: 4/10, Batch: 13/29, Batch_Loss_Train: 3.983
2024-06-21 14:29:05,328 - INFO: Epoch: 4/10, Batch: 14/29, Batch_Loss_Train: 3.663
2024-06-21 14:29:05,738 - INFO: Epoch: 4/10, Batch: 15/29, Batch_Loss_Train: 4.076
2024-06-21 14:29:06,053 - INFO: Epoch: 4/10, Batch: 16/29, Batch_Loss_Train: 4.176
2024-06-21 14:29:06,472 - INFO: Epoch: 4/10, Batch: 17/29, Batch_Loss_Train: 4.080
2024-06-21 14:29:06,774 - INFO: Epoch: 4/10, Batch: 18/29, Batch_Loss_Train: 4.621
2024-06-21 14:29:07,177 - INFO: Epoch: 4/10, Batch: 19/29, Batch_Loss_Train: 3.972
2024-06-21 14:29:07,487 - INFO: Epoch: 4/10, Batch: 20/29, Batch_Loss_Train: 3.423
2024-06-21 14:29:07,895 - INFO: Epoch: 4/10, Batch: 21/29, Batch_Loss_Train: 3.843
2024-06-21 14:29:08,198 - INFO: Epoch: 4/10, Batch: 22/29, Batch_Loss_Train: 3.206
2024-06-21 14:29:08,599 - INFO: Epoch: 4/10, Batch: 23/29, Batch_Loss_Train: 4.126
2024-06-21 14:29:08,915 - INFO: Epoch: 4/10, Batch: 24/29, Batch_Loss_Train: 4.560
2024-06-21 14:29:09,323 - INFO: Epoch: 4/10, Batch: 25/29, Batch_Loss_Train: 3.790
2024-06-21 14:29:09,623 - INFO: Epoch: 4/10, Batch: 26/29, Batch_Loss_Train: 4.162
2024-06-21 14:29:10,017 - INFO: Epoch: 4/10, Batch: 27/29, Batch_Loss_Train: 3.715
2024-06-21 14:29:10,330 - INFO: Epoch: 4/10, Batch: 28/29, Batch_Loss_Train: 3.819
2024-06-21 14:29:10,545 - INFO: Epoch: 4/10, Batch: 29/29, Batch_Loss_Train: 4.103
2024-06-21 14:29:21,566 - INFO: 4/10 final results:
2024-06-21 14:29:21,566 - INFO: Training loss: 3.916.
2024-06-21 14:29:21,566 - INFO: Training MAE: 3.912.
2024-06-21 14:29:21,567 - INFO: Training MSE: 28.211.
2024-06-21 14:29:41,895 - INFO: Epoch: 4/10, Loss_train: 3.915808447476091, Loss_val: 4.285208586988778
2024-06-21 14:29:41,895 - INFO: Best internal validation val_loss: 4.181 at epoch: 3.
2024-06-21 14:29:41,895 - INFO: Epoch 5/10...
2024-06-21 14:29:41,895 - INFO: Learning rate: 4.6201611404555185e-05.
2024-06-21 14:29:41,895 - INFO: Batch size: 32.
2024-06-21 14:29:41,899 - INFO: Dataset:
2024-06-21 14:29:41,899 - INFO: Batch size:
2024-06-21 14:29:41,899 - INFO: Number of workers:
2024-06-21 14:29:43,043 - INFO: Epoch: 5/10, Batch: 1/29, Batch_Loss_Train: 4.318
2024-06-21 14:29:43,352 - INFO: Epoch: 5/10, Batch: 2/29, Batch_Loss_Train: 3.399
2024-06-21 14:29:43,762 - INFO: Epoch: 5/10, Batch: 3/29, Batch_Loss_Train: 3.205
2024-06-21 14:29:44,082 - INFO: Epoch: 5/10, Batch: 4/29, Batch_Loss_Train: 4.206
2024-06-21 14:29:44,482 - INFO: Epoch: 5/10, Batch: 5/29, Batch_Loss_Train: 3.926
2024-06-21 14:29:44,799 - INFO: Epoch: 5/10, Batch: 6/29, Batch_Loss_Train: 4.273
2024-06-21 14:29:45,201 - INFO: Epoch: 5/10, Batch: 7/29, Batch_Loss_Train: 3.290
2024-06-21 14:29:45,519 - INFO: Epoch: 5/10, Batch: 8/29, Batch_Loss_Train: 4.309
2024-06-21 14:29:45,912 - INFO: Epoch: 5/10, Batch: 9/29, Batch_Loss_Train: 3.615
2024-06-21 14:29:46,223 - INFO: Epoch: 5/10, Batch: 10/29, Batch_Loss_Train: 4.401
2024-06-21 14:29:46,620 - INFO: Epoch: 5/10, Batch: 11/29, Batch_Loss_Train: 3.424
2024-06-21 14:29:46,939 - INFO: Epoch: 5/10, Batch: 12/29, Batch_Loss_Train: 3.840
2024-06-21 14:29:47,349 - INFO: Epoch: 5/10, Batch: 13/29, Batch_Loss_Train: 3.487
2024-06-21 14:29:47,669 - INFO: Epoch: 5/10, Batch: 14/29, Batch_Loss_Train: 3.197
2024-06-21 14:29:48,078 - INFO: Epoch: 5/10, Batch: 15/29, Batch_Loss_Train: 3.578
2024-06-21 14:29:48,395 - INFO: Epoch: 5/10, Batch: 16/29, Batch_Loss_Train: 3.609
2024-06-21 14:29:48,801 - INFO: Epoch: 5/10, Batch: 17/29, Batch_Loss_Train: 3.662
2024-06-21 14:29:49,119 - INFO: Epoch: 5/10, Batch: 18/29, Batch_Loss_Train: 3.148
2024-06-21 14:29:49,521 - INFO: Epoch: 5/10, Batch: 19/29, Batch_Loss_Train: 3.603
2024-06-21 14:29:49,834 - INFO: Epoch: 5/10, Batch: 20/29, Batch_Loss_Train: 3.453
2024-06-21 14:29:50,233 - INFO: Epoch: 5/10, Batch: 21/29, Batch_Loss_Train: 3.468
2024-06-21 14:29:50,551 - INFO: Epoch: 5/10, Batch: 22/29, Batch_Loss_Train: 4.273
2024-06-21 14:29:50,940 - INFO: Epoch: 5/10, Batch: 23/29, Batch_Loss_Train: 3.481
2024-06-21 14:29:51,258 - INFO: Epoch: 5/10, Batch: 24/29, Batch_Loss_Train: 3.783
2024-06-21 14:29:51,647 - INFO: Epoch: 5/10, Batch: 25/29, Batch_Loss_Train: 3.469
2024-06-21 14:29:51,961 - INFO: Epoch: 5/10, Batch: 26/29, Batch_Loss_Train: 3.461
2024-06-21 14:29:52,345 - INFO: Epoch: 5/10, Batch: 27/29, Batch_Loss_Train: 3.587
2024-06-21 14:29:52,659 - INFO: Epoch: 5/10, Batch: 28/29, Batch_Loss_Train: 3.619
2024-06-21 14:29:52,869 - INFO: Epoch: 5/10, Batch: 29/29, Batch_Loss_Train: 3.154
2024-06-21 14:30:03,884 - INFO: 5/10 final results:
2024-06-21 14:30:03,885 - INFO: Training loss: 3.663.
2024-06-21 14:30:03,885 - INFO: Training MAE: 3.673.
2024-06-21 14:30:03,885 - INFO: Training MSE: 25.375.
2024-06-21 14:30:24,294 - INFO: Epoch: 5/10, Loss_train: 3.6633987180117904, Loss_val: 3.7212145492948334
2024-06-21 14:30:24,353 - INFO: Saved new best metric model for epoch 5.
2024-06-21 14:30:24,354 - INFO: Best internal validation val_loss: 3.721 at epoch: 5.
2024-06-21 14:30:24,354 - INFO: Epoch 6/10...
2024-06-21 14:30:24,354 - INFO: Learning rate: 4.6201611404555185e-05.
2024-06-21 14:30:24,354 - INFO: Batch size: 32.
2024-06-21 14:30:24,357 - INFO: Dataset:
2024-06-21 14:30:24,357 - INFO: Batch size:
2024-06-21 14:30:24,357 - INFO: Number of workers:
2024-06-21 14:30:25,482 - INFO: Epoch: 6/10, Batch: 1/29, Batch_Loss_Train: 3.354
2024-06-21 14:30:25,802 - INFO: Epoch: 6/10, Batch: 2/29, Batch_Loss_Train: 3.342
2024-06-21 14:30:26,183 - INFO: Epoch: 6/10, Batch: 3/29, Batch_Loss_Train: 3.602
2024-06-21 14:30:26,501 - INFO: Epoch: 6/10, Batch: 4/29, Batch_Loss_Train: 3.607
2024-06-21 14:30:26,914 - INFO: Epoch: 6/10, Batch: 5/29, Batch_Loss_Train: 3.600
2024-06-21 14:30:27,216 - INFO: Epoch: 6/10, Batch: 6/29, Batch_Loss_Train: 3.336
2024-06-21 14:30:27,597 - INFO: Epoch: 6/10, Batch: 7/29, Batch_Loss_Train: 3.782
2024-06-21 14:30:27,912 - INFO: Epoch: 6/10, Batch: 8/29, Batch_Loss_Train: 3.647
2024-06-21 14:30:28,333 - INFO: Epoch: 6/10, Batch: 9/29, Batch_Loss_Train: 3.236
2024-06-21 14:30:28,630 - INFO: Epoch: 6/10, Batch: 10/29, Batch_Loss_Train: 3.686
2024-06-21 14:30:29,002 - INFO: Epoch: 6/10, Batch: 11/29, Batch_Loss_Train: 3.200
2024-06-21 14:30:29,320 - INFO: Epoch: 6/10, Batch: 12/29, Batch_Loss_Train: 3.597
2024-06-21 14:30:29,753 - INFO: Epoch: 6/10, Batch: 13/29, Batch_Loss_Train: 2.715
2024-06-21 14:30:30,058 - INFO: Epoch: 6/10, Batch: 14/29, Batch_Loss_Train: 3.657
2024-06-21 14:30:30,443 - INFO: Epoch: 6/10, Batch: 15/29, Batch_Loss_Train: 3.604
2024-06-21 14:30:30,746 - INFO: Epoch: 6/10, Batch: 16/29, Batch_Loss_Train: 3.995
2024-06-21 14:30:31,181 - INFO: Epoch: 6/10, Batch: 17/29, Batch_Loss_Train: 3.524
2024-06-21 14:30:31,483 - INFO: Epoch: 6/10, Batch: 18/29, Batch_Loss_Train: 3.344
2024-06-21 14:30:31,857 - INFO: Epoch: 6/10, Batch: 19/29, Batch_Loss_Train: 3.598
2024-06-21 14:30:32,156 - INFO: Epoch: 6/10, Batch: 20/29, Batch_Loss_Train: 3.306
2024-06-21 14:30:32,574 - INFO: Epoch: 6/10, Batch: 21/29, Batch_Loss_Train: 3.543
2024-06-21 14:30:32,878 - INFO: Epoch: 6/10, Batch: 22/29, Batch_Loss_Train: 2.683
2024-06-21 14:30:33,257 - INFO: Epoch: 6/10, Batch: 23/29, Batch_Loss_Train: 3.078
2024-06-21 14:30:33,573 - INFO: Epoch: 6/10, Batch: 24/29, Batch_Loss_Train: 3.641
2024-06-21 14:30:33,994 - INFO: Epoch: 6/10, Batch: 25/29, Batch_Loss_Train: 3.219
2024-06-21 14:30:34,293 - INFO: Epoch: 6/10, Batch: 26/29, Batch_Loss_Train: 2.871
2024-06-21 14:30:34,663 - INFO: Epoch: 6/10, Batch: 27/29, Batch_Loss_Train: 3.030
2024-06-21 14:30:34,963 - INFO: Epoch: 6/10, Batch: 28/29, Batch_Loss_Train: 3.366
2024-06-21 14:30:35,173 - INFO: Epoch: 6/10, Batch: 29/29, Batch_Loss_Train: 3.201
2024-06-21 14:30:46,151 - INFO: 6/10 final results:
2024-06-21 14:30:46,151 - INFO: Training loss: 3.392.
2024-06-21 14:30:46,151 - INFO: Training MAE: 3.396.
2024-06-21 14:30:46,151 - INFO: Training MSE: 22.707.
2024-06-21 14:31:06,895 - INFO: Epoch: 6/10, Loss_train: 3.3918782760357034, Loss_val: 3.326195141364788
2024-06-21 14:31:06,954 - INFO: Saved new best metric model for epoch 6.
2024-06-21 14:31:06,954 - INFO: Best internal validation val_loss: 3.326 at epoch: 6.
2024-06-21 14:31:06,955 - INFO: Epoch 7/10...
2024-06-21 14:31:06,955 - INFO: Learning rate: 4.6201611404555185e-05.
2024-06-21 14:31:06,955 - INFO: Batch size: 32.
2024-06-21 14:31:06,958 - INFO: Dataset:
2024-06-21 14:31:06,958 - INFO: Batch size:
2024-06-21 14:31:06,958 - INFO: Number of workers:
2024-06-21 14:31:08,109 - INFO: Epoch: 7/10, Batch: 1/29, Batch_Loss_Train: 3.325
2024-06-21 14:31:08,419 - INFO: Epoch: 7/10, Batch: 2/29, Batch_Loss_Train: 3.734
2024-06-21 14:31:08,830 - INFO: Epoch: 7/10, Batch: 3/29, Batch_Loss_Train: 3.165
2024-06-21 14:31:09,152 - INFO: Epoch: 7/10, Batch: 4/29, Batch_Loss_Train: 3.510
2024-06-21 14:31:09,566 - INFO: Epoch: 7/10, Batch: 5/29, Batch_Loss_Train: 3.464
2024-06-21 14:31:09,870 - INFO: Epoch: 7/10, Batch: 6/29, Batch_Loss_Train: 3.243
2024-06-21 14:31:10,271 - INFO: Epoch: 7/10, Batch: 7/29, Batch_Loss_Train: 3.005
2024-06-21 14:31:10,588 - INFO: Epoch: 7/10, Batch: 8/29, Batch_Loss_Train: 3.278
2024-06-21 14:31:11,002 - INFO: Epoch: 7/10, Batch: 9/29, Batch_Loss_Train: 3.874
2024-06-21 14:31:11,302 - INFO: Epoch: 7/10, Batch: 10/29, Batch_Loss_Train: 3.460
2024-06-21 14:31:11,702 - INFO: Epoch: 7/10, Batch: 11/29, Batch_Loss_Train: 3.011
2024-06-21 14:31:12,021 - INFO: Epoch: 7/10, Batch: 12/29, Batch_Loss_Train: 2.835
2024-06-21 14:31:12,448 - INFO: Epoch: 7/10, Batch: 13/29, Batch_Loss_Train: 3.564
2024-06-21 14:31:12,757 - INFO: Epoch: 7/10, Batch: 14/29, Batch_Loss_Train: 2.971
2024-06-21 14:31:13,172 - INFO: Epoch: 7/10, Batch: 15/29, Batch_Loss_Train: 2.898
2024-06-21 14:31:13,490 - INFO: Epoch: 7/10, Batch: 16/29, Batch_Loss_Train: 3.437
2024-06-21 14:31:13,913 - INFO: Epoch: 7/10, Batch: 17/29, Batch_Loss_Train: 3.643
2024-06-21 14:31:14,219 - INFO: Epoch: 7/10, Batch: 18/29, Batch_Loss_Train: 3.030
2024-06-21 14:31:14,626 - INFO: Epoch: 7/10, Batch: 19/29, Batch_Loss_Train: 3.353
2024-06-21 14:31:14,941 - INFO: Epoch: 7/10, Batch: 20/29, Batch_Loss_Train: 3.061
2024-06-21 14:31:15,360 - INFO: Epoch: 7/10, Batch: 21/29, Batch_Loss_Train: 3.242
2024-06-21 14:31:15,667 - INFO: Epoch: 7/10, Batch: 22/29, Batch_Loss_Train: 2.890
2024-06-21 14:31:16,074 - INFO: Epoch: 7/10, Batch: 23/29, Batch_Loss_Train: 2.821
2024-06-21 14:31:16,394 - INFO: Epoch: 7/10, Batch: 24/29, Batch_Loss_Train: 3.275
2024-06-21 14:31:16,805 - INFO: Epoch: 7/10, Batch: 25/29, Batch_Loss_Train: 3.192
2024-06-21 14:31:17,106 - INFO: Epoch: 7/10, Batch: 26/29, Batch_Loss_Train: 3.137
2024-06-21 14:31:17,500 - INFO: Epoch: 7/10, Batch: 27/29, Batch_Loss_Train: 3.113
2024-06-21 14:31:17,813 - INFO: Epoch: 7/10, Batch: 28/29, Batch_Loss_Train: 3.033
2024-06-21 14:31:18,029 - INFO: Epoch: 7/10, Batch: 29/29, Batch_Loss_Train: 3.241
2024-06-21 14:31:28,472 - INFO: 7/10 final results:
2024-06-21 14:31:28,472 - INFO: Training loss: 3.235.
2024-06-21 14:31:28,472 - INFO: Training MAE: 3.234.
2024-06-21 14:31:28,472 - INFO: Training MSE: 20.627.
2024-06-21 14:31:48,621 - INFO: Epoch: 7/10, Loss_train: 3.2345996067441742, Loss_val: 3.244410227084982
2024-06-21 14:31:48,677 - INFO: Saved new best metric model for epoch 7.
2024-06-21 14:31:48,677 - INFO: Best internal validation val_loss: 3.244 at epoch: 7.
2024-06-21 14:31:48,677 - INFO: Epoch 8/10...
2024-06-21 14:31:48,677 - INFO: Learning rate: 4.6201611404555185e-05.
2024-06-21 14:31:48,677 - INFO: Batch size: 32.
2024-06-21 14:31:48,680 - INFO: Dataset:
2024-06-21 14:31:48,680 - INFO: Batch size:
2024-06-21 14:31:48,680 - INFO: Number of workers:
2024-06-21 14:31:49,815 - INFO: Epoch: 8/10, Batch: 1/29, Batch_Loss_Train: 2.955
2024-06-21 14:31:50,138 - INFO: Epoch: 8/10, Batch: 2/29, Batch_Loss_Train: 2.882
2024-06-21 14:31:50,523 - INFO: Epoch: 8/10, Batch: 3/29, Batch_Loss_Train: 3.039
2024-06-21 14:31:50,842 - INFO: Epoch: 8/10, Batch: 4/29, Batch_Loss_Train: 2.720
2024-06-21 14:31:51,255 - INFO: Epoch: 8/10, Batch: 5/29, Batch_Loss_Train: 2.741
2024-06-21 14:31:51,563 - INFO: Epoch: 8/10, Batch: 6/29, Batch_Loss_Train: 3.475
2024-06-21 14:31:51,958 - INFO: Epoch: 8/10, Batch: 7/29, Batch_Loss_Train: 2.886
2024-06-21 14:31:52,278 - INFO: Epoch: 8/10, Batch: 8/29, Batch_Loss_Train: 2.807
2024-06-21 14:31:52,706 - INFO: Epoch: 8/10, Batch: 9/29, Batch_Loss_Train: 3.192
2024-06-21 14:31:53,004 - INFO: Epoch: 8/10, Batch: 10/29, Batch_Loss_Train: 2.884
2024-06-21 14:31:53,389 - INFO: Epoch: 8/10, Batch: 11/29, Batch_Loss_Train: 2.989
2024-06-21 14:31:53,707 - INFO: Epoch: 8/10, Batch: 12/29, Batch_Loss_Train: 3.158
2024-06-21 14:31:54,139 - INFO: Epoch: 8/10, Batch: 13/29, Batch_Loss_Train: 2.845
2024-06-21 14:31:54,445 - INFO: Epoch: 8/10, Batch: 14/29, Batch_Loss_Train: 2.944
2024-06-21 14:31:54,841 - INFO: Epoch: 8/10, Batch: 15/29, Batch_Loss_Train: 2.737
2024-06-21 14:31:55,157 - INFO: Epoch: 8/10, Batch: 16/29, Batch_Loss_Train: 2.882
2024-06-21 14:31:55,587 - INFO: Epoch: 8/10, Batch: 17/29, Batch_Loss_Train: 3.074
2024-06-21 14:31:55,890 - INFO: Epoch: 8/10, Batch: 18/29, Batch_Loss_Train: 2.626
2024-06-21 14:31:56,279 - INFO: Epoch: 8/10, Batch: 19/29, Batch_Loss_Train: 3.065
2024-06-21 14:31:56,590 - INFO: Epoch: 8/10, Batch: 20/29, Batch_Loss_Train: 2.863
2024-06-21 14:31:57,012 - INFO: Epoch: 8/10, Batch: 21/29, Batch_Loss_Train: 2.721
2024-06-21 14:31:57,316 - INFO: Epoch: 8/10, Batch: 22/29, Batch_Loss_Train: 2.750
2024-06-21 14:31:57,707 - INFO: Epoch: 8/10, Batch: 23/29, Batch_Loss_Train: 3.054
2024-06-21 14:31:58,025 - INFO: Epoch: 8/10, Batch: 24/29, Batch_Loss_Train: 2.765
2024-06-21 14:31:58,447 - INFO: Epoch: 8/10, Batch: 25/29, Batch_Loss_Train: 3.133
2024-06-21 14:31:58,749 - INFO: Epoch: 8/10, Batch: 26/29, Batch_Loss_Train: 3.169
2024-06-21 14:31:59,133 - INFO: Epoch: 8/10, Batch: 27/29, Batch_Loss_Train: 3.466
2024-06-21 14:31:59,447 - INFO: Epoch: 8/10, Batch: 28/29, Batch_Loss_Train: 3.044
2024-06-21 14:31:59,669 - INFO: Epoch: 8/10, Batch: 29/29, Batch_Loss_Train: 3.098
2024-06-21 14:32:10,623 - INFO: 8/10 final results:
2024-06-21 14:32:10,623 - INFO: Training loss: 2.964.
2024-06-21 14:32:10,623 - INFO: Training MAE: 2.962.
2024-06-21 14:32:10,623 - INFO: Training MSE: 18.269.
2024-06-21 14:32:31,264 - INFO: Epoch: 8/10, Loss_train: 2.9642478433148614, Loss_val: 2.945225173029406
2024-06-21 14:32:31,322 - INFO: Saved new best metric model for epoch 8.
2024-06-21 14:32:31,322 - INFO: Best internal validation val_loss: 2.945 at epoch: 8.
2024-06-21 14:32:31,322 - INFO: Epoch 9/10...
2024-06-21 14:32:31,322 - INFO: Learning rate: 4.6201611404555185e-05.
2024-06-21 14:32:31,322 - INFO: Batch size: 32.
2024-06-21 14:32:31,325 - INFO: Dataset:
2024-06-21 14:32:31,326 - INFO: Batch size:
2024-06-21 14:32:31,326 - INFO: Number of workers:
2024-06-21 14:32:32,467 - INFO: Epoch: 9/10, Batch: 1/29, Batch_Loss_Train: 2.403
2024-06-21 14:32:32,778 - INFO: Epoch: 9/10, Batch: 2/29, Batch_Loss_Train: 3.231
2024-06-21 14:32:33,204 - INFO: Epoch: 9/10, Batch: 3/29, Batch_Loss_Train: 2.703
2024-06-21 14:32:33,514 - INFO: Epoch: 9/10, Batch: 4/29, Batch_Loss_Train: 2.972
2024-06-21 14:32:33,932 - INFO: Epoch: 9/10, Batch: 5/29, Batch_Loss_Train: 2.862
2024-06-21 14:32:34,237 - INFO: Epoch: 9/10, Batch: 6/29, Batch_Loss_Train: 2.504
2024-06-21 14:32:34,642 - INFO: Epoch: 9/10, Batch: 7/29, Batch_Loss_Train: 2.915
2024-06-21 14:32:34,949 - INFO: Epoch: 9/10, Batch: 8/29, Batch_Loss_Train: 2.477
2024-06-21 14:32:35,361 - INFO: Epoch: 9/10, Batch: 9/29, Batch_Loss_Train: 3.092
2024-06-21 14:32:35,664 - INFO: Epoch: 9/10, Batch: 10/29, Batch_Loss_Train: 2.719
2024-06-21 14:32:36,081 - INFO: Epoch: 9/10, Batch: 11/29, Batch_Loss_Train: 2.932
2024-06-21 14:32:36,391 - INFO: Epoch: 9/10, Batch: 12/29, Batch_Loss_Train: 2.849
2024-06-21 14:32:36,819 - INFO: Epoch: 9/10, Batch: 13/29, Batch_Loss_Train: 3.259
2024-06-21 14:32:37,128 - INFO: Epoch: 9/10, Batch: 14/29, Batch_Loss_Train: 2.892
2024-06-21 14:32:37,553 - INFO: Epoch: 9/10, Batch: 15/29, Batch_Loss_Train: 3.128
2024-06-21 14:32:37,860 - INFO: Epoch: 9/10, Batch: 16/29, Batch_Loss_Train: 2.766
2024-06-21 14:32:38,274 - INFO: Epoch: 9/10, Batch: 17/29, Batch_Loss_Train: 2.693
2024-06-21 14:32:38,579 - INFO: Epoch: 9/10, Batch: 18/29, Batch_Loss_Train: 2.566
2024-06-21 14:32:39,002 - INFO: Epoch: 9/10, Batch: 19/29, Batch_Loss_Train: 2.618
2024-06-21 14:32:39,302 - INFO: Epoch: 9/10, Batch: 20/29, Batch_Loss_Train: 2.690
2024-06-21 14:32:39,709 - INFO: Epoch: 9/10, Batch: 21/29, Batch_Loss_Train: 2.765
2024-06-21 14:32:40,017 - INFO: Epoch: 9/10, Batch: 22/29, Batch_Loss_Train: 3.186
2024-06-21 14:32:40,449 - INFO: Epoch: 9/10, Batch: 23/29, Batch_Loss_Train: 2.909
2024-06-21 14:32:40,758 - INFO: Epoch: 9/10, Batch: 24/29, Batch_Loss_Train: 2.649
2024-06-21 14:32:41,164 - INFO: Epoch: 9/10, Batch: 25/29, Batch_Loss_Train: 2.829
2024-06-21 14:32:41,469 - INFO: Epoch: 9/10, Batch: 26/29, Batch_Loss_Train: 3.074
2024-06-21 14:32:41,892 - INFO: Epoch: 9/10, Batch: 27/29, Batch_Loss_Train: 2.811
2024-06-21 14:32:42,196 - INFO: Epoch: 9/10, Batch: 28/29, Batch_Loss_Train: 2.994
2024-06-21 14:32:42,413 - INFO: Epoch: 9/10, Batch: 29/29, Batch_Loss_Train: 2.993
2024-06-21 14:32:53,592 - INFO: 9/10 final results:
2024-06-21 14:32:53,593 - INFO: Training loss: 2.844.
2024-06-21 14:32:53,593 - INFO: Training MAE: 2.841.
2024-06-21 14:32:53,593 - INFO: Training MSE: 16.281.
2024-06-21 14:33:13,531 - INFO: Epoch: 9/10, Loss_train: 2.8441264300510802, Loss_val: 2.810418128967285
2024-06-21 14:33:13,588 - INFO: Saved new best metric model for epoch 9.
2024-06-21 14:33:13,588 - INFO: Best internal validation val_loss: 2.810 at epoch: 9.
2024-06-21 14:33:13,588 - INFO: Epoch 10/10...
2024-06-21 14:33:13,588 - INFO: Learning rate: 4.6201611404555185e-05.
2024-06-21 14:33:13,588 - INFO: Batch size: 32.
2024-06-21 14:33:13,592 - INFO: Dataset:
2024-06-21 14:33:13,592 - INFO: Batch size:
2024-06-21 14:33:13,592 - INFO: Number of workers:
2024-06-21 14:33:14,735 - INFO: Epoch: 10/10, Batch: 1/29, Batch_Loss_Train: 2.572
2024-06-21 14:33:15,056 - INFO: Epoch: 10/10, Batch: 2/29, Batch_Loss_Train: 3.066
2024-06-21 14:33:15,439 - INFO: Epoch: 10/10, Batch: 3/29, Batch_Loss_Train: 2.457
2024-06-21 14:33:15,758 - INFO: Epoch: 10/10, Batch: 4/29, Batch_Loss_Train: 2.624
2024-06-21 14:33:16,159 - INFO: Epoch: 10/10, Batch: 5/29, Batch_Loss_Train: 2.429
2024-06-21 14:33:16,486 - INFO: Epoch: 10/10, Batch: 6/29, Batch_Loss_Train: 2.722
2024-06-21 14:33:16,857 - INFO: Epoch: 10/10, Batch: 7/29, Batch_Loss_Train: 2.727
2024-06-21 14:33:17,172 - INFO: Epoch: 10/10, Batch: 8/29, Batch_Loss_Train: 2.377
2024-06-21 14:33:17,563 - INFO: Epoch: 10/10, Batch: 9/29, Batch_Loss_Train: 2.272
2024-06-21 14:33:17,894 - INFO: Epoch: 10/10, Batch: 10/29, Batch_Loss_Train: 2.552
2024-06-21 14:33:18,274 - INFO: Epoch: 10/10, Batch: 11/29, Batch_Loss_Train: 2.702
2024-06-21 14:33:18,591 - INFO: Epoch: 10/10, Batch: 12/29, Batch_Loss_Train: 2.967
2024-06-21 14:33:18,999 - INFO: Epoch: 10/10, Batch: 13/29, Batch_Loss_Train: 2.654
2024-06-21 14:33:19,327 - INFO: Epoch: 10/10, Batch: 14/29, Batch_Loss_Train: 2.822
2024-06-21 14:33:19,732 - INFO: Epoch: 10/10, Batch: 15/29, Batch_Loss_Train: 2.898
2024-06-21 14:33:20,050 - INFO: Epoch: 10/10, Batch: 16/29, Batch_Loss_Train: 2.661
2024-06-21 14:33:20,460 - INFO: Epoch: 10/10, Batch: 17/29, Batch_Loss_Train: 2.724
2024-06-21 14:33:20,789 - INFO: Epoch: 10/10, Batch: 18/29, Batch_Loss_Train: 2.632
2024-06-21 14:33:21,183 - INFO: Epoch: 10/10, Batch: 19/29, Batch_Loss_Train: 2.122
2024-06-21 14:33:21,498 - INFO: Epoch: 10/10, Batch: 20/29, Batch_Loss_Train: 2.336
2024-06-21 14:33:21,898 - INFO: Epoch: 10/10, Batch: 21/29, Batch_Loss_Train: 2.822
2024-06-21 14:33:22,229 - INFO: Epoch: 10/10, Batch: 22/29, Batch_Loss_Train: 2.755
2024-06-21 14:33:22,607 - INFO: Epoch: 10/10, Batch: 23/29, Batch_Loss_Train: 2.541
2024-06-21 14:33:22,925 - INFO: Epoch: 10/10, Batch: 24/29, Batch_Loss_Train: 2.436
2024-06-21 14:33:23,314 - INFO: Epoch: 10/10, Batch: 25/29, Batch_Loss_Train: 2.573
2024-06-21 14:33:23,640 - INFO: Epoch: 10/10, Batch: 26/29, Batch_Loss_Train: 2.491
2024-06-21 14:33:24,013 - INFO: Epoch: 10/10, Batch: 27/29, Batch_Loss_Train: 2.153
2024-06-21 14:33:24,326 - INFO: Epoch: 10/10, Batch: 28/29, Batch_Loss_Train: 2.703
2024-06-21 14:33:24,542 - INFO: Epoch: 10/10, Batch: 29/29, Batch_Loss_Train: 2.534
2024-06-21 14:33:35,522 - INFO: 10/10 final results:
2024-06-21 14:33:35,522 - INFO: Training loss: 2.597.
2024-06-21 14:33:35,522 - INFO: Training MAE: 2.599.
2024-06-21 14:33:35,522 - INFO: Training MSE: 13.552.
2024-06-21 14:33:55,990 - INFO: Epoch: 10/10, Loss_train: 2.597441944582709, Loss_val: 2.8403395044392554
2024-06-21 14:33:55,990 - INFO: Best internal validation val_loss: 2.810 at epoch: 9.
2024-06-21 14:34:39,855 - INFO: Experiment has been saved in 20240621_143439_341_Dual_DCNN_LReLu_0_9_tr_2.61_val_2.81_test_3.31 folder.
2024-06-21 14:34:39,855 - INFO: Fold: 1
2024-06-21 14:34:39,856 - INFO: Train Set: 910/1970, percent: 0.462
2024-06-21 14:34:39,856 - INFO: Val Set: 910/1970, percent: 0.462
2024-06-21 14:34:39,856 - INFO: Test Set: 150/1970, percent: 0.076
2024-06-21 14:34:39,988 - INFO: To_device: False.
2024-06-21 14:34:39,989 - INFO: Transformers have been made successfully.
2024-06-21 14:34:39,990 - INFO: Dataset type: cache.
2024-06-21 14:34:39,990 - INFO: Dataloader type: standard.
2024-06-21 14:36:30,797 - INFO: Train dataloader arguments.
2024-06-21 14:36:30,797 - INFO: 	Batch_size: 32.
2024-06-21 14:36:30,797 - INFO: 	Shuffle: True.
2024-06-21 14:36:30,797 - INFO: 	Sampler: None.
2024-06-21 14:36:30,797 - INFO: 	Num_workers: 4.
2024-06-21 14:36:30,797 - INFO: 	Drop_last: False.
2024-06-21 14:36:31,070 - INFO: Dual_DCNN_LReLU(
  (conv_blocks_fixed): ModuleList(
    (0): conv_block_two(
      (pad1): conv3d_padding_same()
      (conv1): Conv3d(1, 8, kernel_size=(1, 6, 6), stride=(2, 2, 2))
      (norm1): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activation1): LeakyReLU(negative_slope=0.1)
      (pad2): conv3d_padding_same()
      (conv2): Conv3d(8, 8, kernel_size=(1, 6, 6), stride=(1, 1, 1))
      (norm2): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activation2): LeakyReLU(negative_slope=0.1)
      (max_pooling): MaxPool3d(kernel_size=3, stride=1, padding=0, dilation=1, ceil_mode=False)
    )
    (1): conv_block_two(
      (pad1): conv3d_padding_same()
      (conv1): Conv3d(8, 8, kernel_size=(1, 3, 3), stride=(2, 2, 2))
      (norm1): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activation1): LeakyReLU(negative_slope=0.1)
      (pad2): conv3d_padding_same()
      (conv2): Conv3d(8, 8, kernel_size=(1, 3, 3), stride=(1, 1, 1))
      (norm2): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activation2): LeakyReLU(negative_slope=0.1)
      (max_pooling): MaxPool3d(kernel_size=3, stride=1, padding=0, dilation=1, ceil_mode=False)
    )
    (2): conv_block_two(
      (pad1): conv3d_padding_same()
      (conv1): Conv3d(8, 16, kernel_size=(1, 3, 3), stride=(2, 2, 2))
      (norm1): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activation1): LeakyReLU(negative_slope=0.1)
      (pad2): conv3d_padding_same()
      (conv2): Conv3d(16, 16, kernel_size=(1, 3, 3), stride=(1, 1, 1))
      (norm2): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activation2): LeakyReLU(negative_slope=0.1)
      (max_pooling): MaxPool3d(kernel_size=3, stride=1, padding=0, dilation=1, ceil_mode=False)
    )
    (3): conv_block_two(
      (pad1): conv3d_padding_same()
      (conv1): Conv3d(16, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1))
      (norm1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activation1): LeakyReLU(negative_slope=0.1)
      (pad2): conv3d_padding_same()
      (conv2): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1))
      (norm2): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activation2): LeakyReLU(negative_slope=0.1)
      (max_pooling): MaxPool3d(kernel_size=3, stride=1, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (conv_blocks_moving): ModuleList(
    (0): conv_block_two(
      (pad1): conv3d_padding_same()
      (conv1): Conv3d(1, 8, kernel_size=(1, 6, 6), stride=(2, 2, 2))
      (norm1): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activation1): LeakyReLU(negative_slope=0.1)
      (pad2): conv3d_padding_same()
      (conv2): Conv3d(8, 8, kernel_size=(1, 6, 6), stride=(1, 1, 1))
      (norm2): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activation2): LeakyReLU(negative_slope=0.1)
      (max_pooling): MaxPool3d(kernel_size=3, stride=1, padding=0, dilation=1, ceil_mode=False)
    )
    (1): conv_block_two(
      (pad1): conv3d_padding_same()
      (conv1): Conv3d(8, 8, kernel_size=(1, 3, 3), stride=(2, 2, 2))
      (norm1): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activation1): LeakyReLU(negative_slope=0.1)
      (pad2): conv3d_padding_same()
      (conv2): Conv3d(8, 8, kernel_size=(1, 3, 3), stride=(1, 1, 1))
      (norm2): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activation2): LeakyReLU(negative_slope=0.1)
      (max_pooling): MaxPool3d(kernel_size=3, stride=1, padding=0, dilation=1, ceil_mode=False)
    )
    (2): conv_block_two(
      (pad1): conv3d_padding_same()
      (conv1): Conv3d(8, 16, kernel_size=(1, 3, 3), stride=(2, 2, 2))
      (norm1): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activation1): LeakyReLU(negative_slope=0.1)
      (pad2): conv3d_padding_same()
      (conv2): Conv3d(16, 16, kernel_size=(1, 3, 3), stride=(1, 1, 1))
      (norm2): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activation2): LeakyReLU(negative_slope=0.1)
      (max_pooling): MaxPool3d(kernel_size=3, stride=1, padding=0, dilation=1, ceil_mode=False)
    )
    (3): conv_block_two(
      (pad1): conv3d_padding_same()
      (conv1): Conv3d(16, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1))
      (norm1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activation1): LeakyReLU(negative_slope=0.1)
      (pad2): conv3d_padding_same()
      (conv2): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1))
      (norm2): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activation2): LeakyReLU(negative_slope=0.1)
      (max_pooling): MaxPool3d(kernel_size=3, stride=1, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (linear_layers): ModuleList(
    (0): Dropout(p=0.35973448489278154, inplace=False)
    (1): Linear(in_features=262144, out_features=32, bias=True)
  )
  (out_layer): Output(
    in_features=32, out_features=3, bias=True
    (fc): Linear(in_features=32, out_features=3, bias=True)
  )
)
2024-06-21 14:36:31,077 - INFO: Weight init name: kaiming_uniform.
2024-06-21 14:36:31,810 - INFO: Number of training iterations per epoch: 29.
2024-06-21 14:36:31,810 - INFO: Epoch 1/10...
2024-06-21 14:36:31,810 - INFO: Learning rate: 4.6201611404555185e-05.
2024-06-21 14:36:31,810 - INFO: Batch size: 32.
2024-06-21 14:36:31,811 - INFO: Dataset:
2024-06-21 14:36:31,811 - INFO: Batch size:
2024-06-21 14:36:31,811 - INFO: Number of workers:
2024-06-21 14:36:33,124 - INFO: Epoch: 1/10, Batch: 1/29, Batch_Loss_Train: 6.775
2024-06-21 14:36:33,434 - INFO: Epoch: 1/10, Batch: 2/29, Batch_Loss_Train: 7.827
2024-06-21 14:36:33,831 - INFO: Epoch: 1/10, Batch: 3/29, Batch_Loss_Train: 7.385
2024-06-21 14:36:34,139 - INFO: Epoch: 1/10, Batch: 4/29, Batch_Loss_Train: 6.921
2024-06-21 14:36:34,582 - INFO: Epoch: 1/10, Batch: 5/29, Batch_Loss_Train: 7.085
2024-06-21 14:36:34,883 - INFO: Epoch: 1/10, Batch: 6/29, Batch_Loss_Train: 6.896
2024-06-21 14:36:35,268 - INFO: Epoch: 1/10, Batch: 7/29, Batch_Loss_Train: 7.615
2024-06-21 14:36:35,570 - INFO: Epoch: 1/10, Batch: 8/29, Batch_Loss_Train: 6.600
2024-06-21 14:36:35,993 - INFO: Epoch: 1/10, Batch: 9/29, Batch_Loss_Train: 6.973
2024-06-21 14:36:36,289 - INFO: Epoch: 1/10, Batch: 10/29, Batch_Loss_Train: 6.827
2024-06-21 14:36:36,667 - INFO: Epoch: 1/10, Batch: 11/29, Batch_Loss_Train: 7.140
2024-06-21 14:36:36,975 - INFO: Epoch: 1/10, Batch: 12/29, Batch_Loss_Train: 7.812
2024-06-21 14:36:37,453 - INFO: Epoch: 1/10, Batch: 13/29, Batch_Loss_Train: 8.098
2024-06-21 14:36:37,759 - INFO: Epoch: 1/10, Batch: 14/29, Batch_Loss_Train: 7.158
2024-06-21 14:36:38,159 - INFO: Epoch: 1/10, Batch: 15/29, Batch_Loss_Train: 7.778
2024-06-21 14:36:38,461 - INFO: Epoch: 1/10, Batch: 16/29, Batch_Loss_Train: 6.933
2024-06-21 14:36:38,905 - INFO: Epoch: 1/10, Batch: 17/29, Batch_Loss_Train: 6.741
2024-06-21 14:36:39,210 - INFO: Epoch: 1/10, Batch: 18/29, Batch_Loss_Train: 6.160
2024-06-21 14:36:39,595 - INFO: Epoch: 1/10, Batch: 19/29, Batch_Loss_Train: 6.930
2024-06-21 14:36:39,893 - INFO: Epoch: 1/10, Batch: 20/29, Batch_Loss_Train: 6.908
2024-06-21 14:36:40,332 - INFO: Epoch: 1/10, Batch: 21/29, Batch_Loss_Train: 6.687
2024-06-21 14:36:40,638 - INFO: Epoch: 1/10, Batch: 22/29, Batch_Loss_Train: 7.890
2024-06-21 14:36:41,039 - INFO: Epoch: 1/10, Batch: 23/29, Batch_Loss_Train: 7.530
2024-06-21 14:36:41,346 - INFO: Epoch: 1/10, Batch: 24/29, Batch_Loss_Train: 7.019
2024-06-21 14:36:41,786 - INFO: Epoch: 1/10, Batch: 25/29, Batch_Loss_Train: 6.435
2024-06-21 14:36:42,088 - INFO: Epoch: 1/10, Batch: 26/29, Batch_Loss_Train: 6.624
2024-06-21 14:36:42,480 - INFO: Epoch: 1/10, Batch: 27/29, Batch_Loss_Train: 7.308
2024-06-21 14:36:42,784 - INFO: Epoch: 1/10, Batch: 28/29, Batch_Loss_Train: 6.868
2024-06-21 14:36:43,005 - INFO: Epoch: 1/10, Batch: 29/29, Batch_Loss_Train: 7.023
2024-06-21 14:36:54,067 - INFO: 1/10 final results:
2024-06-21 14:36:54,068 - INFO: Training loss: 7.102.
2024-06-21 14:36:54,068 - INFO: Training MAE: 7.103.
2024-06-21 14:36:54,068 - INFO: Training MSE: 68.710.
2024-06-21 14:37:14,749 - INFO: Epoch: 1/10, Loss_train: 7.101600548316693, Loss_val: 6.889070346437651
2024-06-21 14:37:14,749 - INFO: Best internal validation val_loss: inf at epoch: 0.
2024-06-21 14:37:14,749 - INFO: Epoch 2/10...
2024-06-21 14:37:14,749 - INFO: Learning rate: 4.6201611404555185e-05.
2024-06-21 14:37:14,749 - INFO: Batch size: 32.
2024-06-21 14:37:14,753 - INFO: Dataset:
2024-06-21 14:37:14,753 - INFO: Batch size:
2024-06-21 14:37:14,753 - INFO: Number of workers:
2024-06-21 14:37:16,059 - INFO: Epoch: 2/10, Batch: 1/29, Batch_Loss_Train: 6.109
2024-06-21 14:37:16,369 - INFO: Epoch: 2/10, Batch: 2/29, Batch_Loss_Train: 6.433
2024-06-21 14:37:16,762 - INFO: Epoch: 2/10, Batch: 3/29, Batch_Loss_Train: 6.206
2024-06-21 14:37:17,083 - INFO: Epoch: 2/10, Batch: 4/29, Batch_Loss_Train: 5.745
2024-06-21 14:37:17,526 - INFO: Epoch: 2/10, Batch: 5/29, Batch_Loss_Train: 6.295
2024-06-21 14:37:17,830 - INFO: Epoch: 2/10, Batch: 6/29, Batch_Loss_Train: 5.899
2024-06-21 14:37:18,202 - INFO: Epoch: 2/10, Batch: 7/29, Batch_Loss_Train: 6.376
2024-06-21 14:37:18,506 - INFO: Epoch: 2/10, Batch: 8/29, Batch_Loss_Train: 5.178
2024-06-21 14:37:18,927 - INFO: Epoch: 2/10, Batch: 9/29, Batch_Loss_Train: 5.427
2024-06-21 14:37:19,224 - INFO: Epoch: 2/10, Batch: 10/29, Batch_Loss_Train: 5.729
2024-06-21 14:37:19,606 - INFO: Epoch: 2/10, Batch: 11/29, Batch_Loss_Train: 5.232
2024-06-21 14:37:19,916 - INFO: Epoch: 2/10, Batch: 12/29, Batch_Loss_Train: 5.562
2024-06-21 14:37:20,355 - INFO: Epoch: 2/10, Batch: 13/29, Batch_Loss_Train: 5.627
2024-06-21 14:37:20,665 - INFO: Epoch: 2/10, Batch: 14/29, Batch_Loss_Train: 5.400
2024-06-21 14:37:21,080 - INFO: Epoch: 2/10, Batch: 15/29, Batch_Loss_Train: 6.055
2024-06-21 14:37:21,385 - INFO: Epoch: 2/10, Batch: 16/29, Batch_Loss_Train: 5.142
2024-06-21 14:37:21,820 - INFO: Epoch: 2/10, Batch: 17/29, Batch_Loss_Train: 5.960
2024-06-21 14:37:22,126 - INFO: Epoch: 2/10, Batch: 18/29, Batch_Loss_Train: 5.527
2024-06-21 14:37:22,529 - INFO: Epoch: 2/10, Batch: 19/29, Batch_Loss_Train: 5.941
2024-06-21 14:37:22,829 - INFO: Epoch: 2/10, Batch: 20/29, Batch_Loss_Train: 5.862
2024-06-21 14:37:23,254 - INFO: Epoch: 2/10, Batch: 21/29, Batch_Loss_Train: 5.033
2024-06-21 14:37:23,564 - INFO: Epoch: 2/10, Batch: 22/29, Batch_Loss_Train: 4.868
2024-06-21 14:37:23,977 - INFO: Epoch: 2/10, Batch: 23/29, Batch_Loss_Train: 5.678
2024-06-21 14:37:24,286 - INFO: Epoch: 2/10, Batch: 24/29, Batch_Loss_Train: 5.790
2024-06-21 14:37:24,716 - INFO: Epoch: 2/10, Batch: 25/29, Batch_Loss_Train: 4.758
2024-06-21 14:37:25,018 - INFO: Epoch: 2/10, Batch: 26/29, Batch_Loss_Train: 5.596
2024-06-21 14:37:25,422 - INFO: Epoch: 2/10, Batch: 27/29, Batch_Loss_Train: 4.964
2024-06-21 14:37:25,726 - INFO: Epoch: 2/10, Batch: 28/29, Batch_Loss_Train: 5.502
2024-06-21 14:37:25,951 - INFO: Epoch: 2/10, Batch: 29/29, Batch_Loss_Train: 5.644
2024-06-21 14:37:36,987 - INFO: 2/10 final results:
2024-06-21 14:37:36,988 - INFO: Training loss: 5.639.
2024-06-21 14:37:36,988 - INFO: Training MAE: 5.639.
2024-06-21 14:37:36,988 - INFO: Training MSE: 48.719.
2024-06-21 14:37:57,453 - INFO: Epoch: 2/10, Loss_train: 5.639188914463438, Loss_val: 5.541208941361
2024-06-21 14:37:57,511 - INFO: Saved new best metric model for epoch 2.
2024-06-21 14:37:57,511 - INFO: Best internal validation val_loss: 5.541 at epoch: 2.
2024-06-21 14:37:57,511 - INFO: Epoch 3/10...
2024-06-21 14:37:57,511 - INFO: Learning rate: 4.6201611404555185e-05.
2024-06-21 14:37:57,511 - INFO: Batch size: 32.
2024-06-21 14:37:57,515 - INFO: Dataset:
2024-06-21 14:37:57,515 - INFO: Batch size:
2024-06-21 14:37:57,515 - INFO: Number of workers:
2024-06-21 14:37:58,792 - INFO: Epoch: 3/10, Batch: 1/29, Batch_Loss_Train: 4.394
2024-06-21 14:37:59,131 - INFO: Epoch: 3/10, Batch: 2/29, Batch_Loss_Train: 5.040
2024-06-21 14:37:59,535 - INFO: Epoch: 3/10, Batch: 3/29, Batch_Loss_Train: 4.609
2024-06-21 14:37:59,857 - INFO: Epoch: 3/10, Batch: 4/29, Batch_Loss_Train: 4.916
2024-06-21 14:38:00,260 - INFO: Epoch: 3/10, Batch: 5/29, Batch_Loss_Train: 4.854
2024-06-21 14:38:00,585 - INFO: Epoch: 3/10, Batch: 6/29, Batch_Loss_Train: 5.062
2024-06-21 14:38:00,970 - INFO: Epoch: 3/10, Batch: 7/29, Batch_Loss_Train: 4.929
2024-06-21 14:38:01,285 - INFO: Epoch: 3/10, Batch: 8/29, Batch_Loss_Train: 6.171
2024-06-21 14:38:01,674 - INFO: Epoch: 3/10, Batch: 9/29, Batch_Loss_Train: 4.549
2024-06-21 14:38:01,999 - INFO: Epoch: 3/10, Batch: 10/29, Batch_Loss_Train: 5.214
2024-06-21 14:38:02,377 - INFO: Epoch: 3/10, Batch: 11/29, Batch_Loss_Train: 4.851
2024-06-21 14:38:02,696 - INFO: Epoch: 3/10, Batch: 12/29, Batch_Loss_Train: 4.550
2024-06-21 14:38:03,109 - INFO: Epoch: 3/10, Batch: 13/29, Batch_Loss_Train: 5.120
2024-06-21 14:38:03,439 - INFO: Epoch: 3/10, Batch: 14/29, Batch_Loss_Train: 5.252
2024-06-21 14:38:03,836 - INFO: Epoch: 3/10, Batch: 15/29, Batch_Loss_Train: 4.776
2024-06-21 14:38:04,150 - INFO: Epoch: 3/10, Batch: 16/29, Batch_Loss_Train: 5.186
2024-06-21 14:38:04,551 - INFO: Epoch: 3/10, Batch: 17/29, Batch_Loss_Train: 5.013
2024-06-21 14:38:04,877 - INFO: Epoch: 3/10, Batch: 18/29, Batch_Loss_Train: 4.639
2024-06-21 14:38:05,260 - INFO: Epoch: 3/10, Batch: 19/29, Batch_Loss_Train: 5.020
2024-06-21 14:38:05,568 - INFO: Epoch: 3/10, Batch: 20/29, Batch_Loss_Train: 4.999
2024-06-21 14:38:05,964 - INFO: Epoch: 3/10, Batch: 21/29, Batch_Loss_Train: 4.815
2024-06-21 14:38:06,291 - INFO: Epoch: 3/10, Batch: 22/29, Batch_Loss_Train: 4.525
2024-06-21 14:38:06,678 - INFO: Epoch: 3/10, Batch: 23/29, Batch_Loss_Train: 4.462
2024-06-21 14:38:06,999 - INFO: Epoch: 3/10, Batch: 24/29, Batch_Loss_Train: 4.935
2024-06-21 14:38:07,405 - INFO: Epoch: 3/10, Batch: 25/29, Batch_Loss_Train: 4.908
2024-06-21 14:38:07,732 - INFO: Epoch: 3/10, Batch: 26/29, Batch_Loss_Train: 4.571
2024-06-21 14:38:08,124 - INFO: Epoch: 3/10, Batch: 27/29, Batch_Loss_Train: 4.797
2024-06-21 14:38:08,440 - INFO: Epoch: 3/10, Batch: 28/29, Batch_Loss_Train: 5.335
2024-06-21 14:38:08,665 - INFO: Epoch: 3/10, Batch: 29/29, Batch_Loss_Train: 4.039
2024-06-21 14:38:19,838 - INFO: 3/10 final results:
2024-06-21 14:38:19,838 - INFO: Training loss: 4.880.
2024-06-21 14:38:19,839 - INFO: Training MAE: 4.897.
2024-06-21 14:38:19,839 - INFO: Training MSE: 39.983.
2024-06-21 14:38:40,318 - INFO: Epoch: 3/10, Loss_train: 4.880281925201416, Loss_val: 4.967800830972606
2024-06-21 14:38:40,374 - INFO: Saved new best metric model for epoch 3.
2024-06-21 14:38:40,374 - INFO: Best internal validation val_loss: 4.968 at epoch: 3.
2024-06-21 14:38:40,375 - INFO: Epoch 4/10...
2024-06-21 14:38:40,375 - INFO: Learning rate: 4.6201611404555185e-05.
2024-06-21 14:38:40,375 - INFO: Batch size: 32.
2024-06-21 14:38:40,378 - INFO: Dataset:
2024-06-21 14:38:40,378 - INFO: Batch size:
2024-06-21 14:38:40,379 - INFO: Number of workers:
2024-06-21 14:38:41,636 - INFO: Epoch: 4/10, Batch: 1/29, Batch_Loss_Train: 4.442
2024-06-21 14:38:41,962 - INFO: Epoch: 4/10, Batch: 2/29, Batch_Loss_Train: 4.542
2024-06-21 14:38:42,382 - INFO: Epoch: 4/10, Batch: 3/29, Batch_Loss_Train: 5.320
2024-06-21 14:38:42,710 - INFO: Epoch: 4/10, Batch: 4/29, Batch_Loss_Train: 4.534
2024-06-21 14:38:43,120 - INFO: Epoch: 4/10, Batch: 5/29, Batch_Loss_Train: 4.419
2024-06-21 14:38:43,425 - INFO: Epoch: 4/10, Batch: 6/29, Batch_Loss_Train: 4.102
2024-06-21 14:38:43,845 - INFO: Epoch: 4/10, Batch: 7/29, Batch_Loss_Train: 4.172
2024-06-21 14:38:44,173 - INFO: Epoch: 4/10, Batch: 8/29, Batch_Loss_Train: 4.561
2024-06-21 14:38:44,600 - INFO: Epoch: 4/10, Batch: 9/29, Batch_Loss_Train: 4.190
2024-06-21 14:38:44,899 - INFO: Epoch: 4/10, Batch: 10/29, Batch_Loss_Train: 4.703
2024-06-21 14:38:45,296 - INFO: Epoch: 4/10, Batch: 11/29, Batch_Loss_Train: 3.720
2024-06-21 14:38:45,618 - INFO: Epoch: 4/10, Batch: 12/29, Batch_Loss_Train: 4.742
2024-06-21 14:38:46,039 - INFO: Epoch: 4/10, Batch: 13/29, Batch_Loss_Train: 4.100
2024-06-21 14:38:46,349 - INFO: Epoch: 4/10, Batch: 14/29, Batch_Loss_Train: 4.153
2024-06-21 14:38:46,764 - INFO: Epoch: 4/10, Batch: 15/29, Batch_Loss_Train: 4.482
2024-06-21 14:38:47,082 - INFO: Epoch: 4/10, Batch: 16/29, Batch_Loss_Train: 4.083
2024-06-21 14:38:47,487 - INFO: Epoch: 4/10, Batch: 17/29, Batch_Loss_Train: 4.124
2024-06-21 14:38:47,793 - INFO: Epoch: 4/10, Batch: 18/29, Batch_Loss_Train: 4.107
2024-06-21 14:38:48,198 - INFO: Epoch: 4/10, Batch: 19/29, Batch_Loss_Train: 4.239
2024-06-21 14:38:48,511 - INFO: Epoch: 4/10, Batch: 20/29, Batch_Loss_Train: 4.285
2024-06-21 14:38:48,930 - INFO: Epoch: 4/10, Batch: 21/29, Batch_Loss_Train: 4.589
2024-06-21 14:38:49,238 - INFO: Epoch: 4/10, Batch: 22/29, Batch_Loss_Train: 4.346
2024-06-21 14:38:49,652 - INFO: Epoch: 4/10, Batch: 23/29, Batch_Loss_Train: 4.310
2024-06-21 14:38:49,974 - INFO: Epoch: 4/10, Batch: 24/29, Batch_Loss_Train: 3.932
2024-06-21 14:38:50,392 - INFO: Epoch: 4/10, Batch: 25/29, Batch_Loss_Train: 4.579
2024-06-21 14:38:50,695 - INFO: Epoch: 4/10, Batch: 26/29, Batch_Loss_Train: 4.352
2024-06-21 14:38:51,101 - INFO: Epoch: 4/10, Batch: 27/29, Batch_Loss_Train: 4.930
2024-06-21 14:38:51,417 - INFO: Epoch: 4/10, Batch: 28/29, Batch_Loss_Train: 4.116
2024-06-21 14:38:51,641 - INFO: Epoch: 4/10, Batch: 29/29, Batch_Loss_Train: 3.849
2024-06-21 14:39:02,675 - INFO: 4/10 final results:
2024-06-21 14:39:02,675 - INFO: Training loss: 4.346.
2024-06-21 14:39:02,675 - INFO: Training MAE: 4.355.
2024-06-21 14:39:02,675 - INFO: Training MSE: 32.751.
2024-06-21 14:39:23,311 - INFO: Epoch: 4/10, Loss_train: 4.345613874238113, Loss_val: 4.2820456192411225
2024-06-21 14:39:23,370 - INFO: Saved new best metric model for epoch 4.
2024-06-21 14:39:23,370 - INFO: Best internal validation val_loss: 4.282 at epoch: 4.
2024-06-21 14:39:23,370 - INFO: Epoch 5/10...
2024-06-21 14:39:23,370 - INFO: Learning rate: 4.6201611404555185e-05.
2024-06-21 14:39:23,370 - INFO: Batch size: 32.
2024-06-21 14:39:23,374 - INFO: Dataset:
2024-06-21 14:39:23,374 - INFO: Batch size:
2024-06-21 14:39:23,374 - INFO: Number of workers:
2024-06-21 14:39:24,667 - INFO: Epoch: 5/10, Batch: 1/29, Batch_Loss_Train: 3.751
2024-06-21 14:39:24,977 - INFO: Epoch: 5/10, Batch: 2/29, Batch_Loss_Train: 4.458
2024-06-21 14:39:25,378 - INFO: Epoch: 5/10, Batch: 3/29, Batch_Loss_Train: 4.360
2024-06-21 14:39:25,700 - INFO: Epoch: 5/10, Batch: 4/29, Batch_Loss_Train: 4.182
2024-06-21 14:39:26,127 - INFO: Epoch: 5/10, Batch: 5/29, Batch_Loss_Train: 3.978
2024-06-21 14:39:26,427 - INFO: Epoch: 5/10, Batch: 6/29, Batch_Loss_Train: 3.691
2024-06-21 14:39:26,812 - INFO: Epoch: 5/10, Batch: 7/29, Batch_Loss_Train: 4.005
2024-06-21 14:39:27,127 - INFO: Epoch: 5/10, Batch: 8/29, Batch_Loss_Train: 4.024
2024-06-21 14:39:27,552 - INFO: Epoch: 5/10, Batch: 9/29, Batch_Loss_Train: 4.272
2024-06-21 14:39:27,846 - INFO: Epoch: 5/10, Batch: 10/29, Batch_Loss_Train: 3.708
2024-06-21 14:39:28,231 - INFO: Epoch: 5/10, Batch: 11/29, Batch_Loss_Train: 3.672
2024-06-21 14:39:28,556 - INFO: Epoch: 5/10, Batch: 12/29, Batch_Loss_Train: 3.541
2024-06-21 14:39:29,000 - INFO: Epoch: 5/10, Batch: 13/29, Batch_Loss_Train: 3.748
2024-06-21 14:39:29,310 - INFO: Epoch: 5/10, Batch: 14/29, Batch_Loss_Train: 3.926
2024-06-21 14:39:29,714 - INFO: Epoch: 5/10, Batch: 15/29, Batch_Loss_Train: 3.852
2024-06-21 14:39:30,032 - INFO: Epoch: 5/10, Batch: 16/29, Batch_Loss_Train: 3.830
2024-06-21 14:39:30,458 - INFO: Epoch: 5/10, Batch: 17/29, Batch_Loss_Train: 3.755
2024-06-21 14:39:30,759 - INFO: Epoch: 5/10, Batch: 18/29, Batch_Loss_Train: 3.674
2024-06-21 14:39:31,149 - INFO: Epoch: 5/10, Batch: 19/29, Batch_Loss_Train: 3.751
2024-06-21 14:39:31,463 - INFO: Epoch: 5/10, Batch: 20/29, Batch_Loss_Train: 4.215
2024-06-21 14:39:31,890 - INFO: Epoch: 5/10, Batch: 21/29, Batch_Loss_Train: 4.010
2024-06-21 14:39:32,197 - INFO: Epoch: 5/10, Batch: 22/29, Batch_Loss_Train: 3.270
2024-06-21 14:39:32,585 - INFO: Epoch: 5/10, Batch: 23/29, Batch_Loss_Train: 3.732
2024-06-21 14:39:32,904 - INFO: Epoch: 5/10, Batch: 24/29, Batch_Loss_Train: 3.590
2024-06-21 14:39:33,320 - INFO: Epoch: 5/10, Batch: 25/29, Batch_Loss_Train: 3.680
2024-06-21 14:39:33,621 - INFO: Epoch: 5/10, Batch: 26/29, Batch_Loss_Train: 4.445
2024-06-21 14:39:33,991 - INFO: Epoch: 5/10, Batch: 27/29, Batch_Loss_Train: 3.823
2024-06-21 14:39:34,306 - INFO: Epoch: 5/10, Batch: 28/29, Batch_Loss_Train: 3.252
2024-06-21 14:39:34,516 - INFO: Epoch: 5/10, Batch: 29/29, Batch_Loss_Train: 4.158
2024-06-21 14:39:45,538 - INFO: 5/10 final results:
2024-06-21 14:39:45,539 - INFO: Training loss: 3.874.
2024-06-21 14:39:45,539 - INFO: Training MAE: 3.869.
2024-06-21 14:39:45,539 - INFO: Training MSE: 26.444.
2024-06-21 14:40:06,294 - INFO: Epoch: 5/10, Loss_train: 3.8742159563919594, Loss_val: 4.153464744830954
2024-06-21 14:40:06,353 - INFO: Saved new best metric model for epoch 5.
2024-06-21 14:40:06,353 - INFO: Best internal validation val_loss: 4.153 at epoch: 5.
2024-06-21 14:40:06,353 - INFO: Epoch 6/10...
2024-06-21 14:40:06,353 - INFO: Learning rate: 4.6201611404555185e-05.
2024-06-21 14:40:06,353 - INFO: Batch size: 32.
2024-06-21 14:40:06,357 - INFO: Dataset:
2024-06-21 14:40:06,357 - INFO: Batch size:
2024-06-21 14:40:06,357 - INFO: Number of workers:
2024-06-21 14:40:07,617 - INFO: Epoch: 6/10, Batch: 1/29, Batch_Loss_Train: 3.813
2024-06-21 14:40:07,928 - INFO: Epoch: 6/10, Batch: 2/29, Batch_Loss_Train: 3.753
2024-06-21 14:40:08,331 - INFO: Epoch: 6/10, Batch: 3/29, Batch_Loss_Train: 3.525
2024-06-21 14:40:08,657 - INFO: Epoch: 6/10, Batch: 4/29, Batch_Loss_Train: 3.649
2024-06-21 14:40:09,079 - INFO: Epoch: 6/10, Batch: 5/29, Batch_Loss_Train: 3.393
2024-06-21 14:40:09,384 - INFO: Epoch: 6/10, Batch: 6/29, Batch_Loss_Train: 3.900
2024-06-21 14:40:09,788 - INFO: Epoch: 6/10, Batch: 7/29, Batch_Loss_Train: 3.594
2024-06-21 14:40:10,107 - INFO: Epoch: 6/10, Batch: 8/29, Batch_Loss_Train: 3.379
2024-06-21 14:40:10,508 - INFO: Epoch: 6/10, Batch: 9/29, Batch_Loss_Train: 3.514
2024-06-21 14:40:10,803 - INFO: Epoch: 6/10, Batch: 10/29, Batch_Loss_Train: 3.514
2024-06-21 14:40:11,182 - INFO: Epoch: 6/10, Batch: 11/29, Batch_Loss_Train: 3.390
2024-06-21 14:40:11,501 - INFO: Epoch: 6/10, Batch: 12/29, Batch_Loss_Train: 3.798
2024-06-21 14:40:11,914 - INFO: Epoch: 6/10, Batch: 13/29, Batch_Loss_Train: 3.624
2024-06-21 14:40:12,218 - INFO: Epoch: 6/10, Batch: 14/29, Batch_Loss_Train: 3.408
2024-06-21 14:40:12,634 - INFO: Epoch: 6/10, Batch: 15/29, Batch_Loss_Train: 3.213
2024-06-21 14:40:12,952 - INFO: Epoch: 6/10, Batch: 16/29, Batch_Loss_Train: 3.341
2024-06-21 14:40:13,356 - INFO: Epoch: 6/10, Batch: 17/29, Batch_Loss_Train: 3.012
2024-06-21 14:40:13,663 - INFO: Epoch: 6/10, Batch: 18/29, Batch_Loss_Train: 3.515
2024-06-21 14:40:14,069 - INFO: Epoch: 6/10, Batch: 19/29, Batch_Loss_Train: 3.195
2024-06-21 14:40:14,382 - INFO: Epoch: 6/10, Batch: 20/29, Batch_Loss_Train: 3.563
2024-06-21 14:40:14,801 - INFO: Epoch: 6/10, Batch: 21/29, Batch_Loss_Train: 3.364
2024-06-21 14:40:15,109 - INFO: Epoch: 6/10, Batch: 22/29, Batch_Loss_Train: 3.178
2024-06-21 14:40:15,523 - INFO: Epoch: 6/10, Batch: 23/29, Batch_Loss_Train: 3.708
2024-06-21 14:40:15,844 - INFO: Epoch: 6/10, Batch: 24/29, Batch_Loss_Train: 3.366
2024-06-21 14:40:16,263 - INFO: Epoch: 6/10, Batch: 25/29, Batch_Loss_Train: 3.239
2024-06-21 14:40:16,566 - INFO: Epoch: 6/10, Batch: 26/29, Batch_Loss_Train: 2.748
2024-06-21 14:40:16,971 - INFO: Epoch: 6/10, Batch: 27/29, Batch_Loss_Train: 3.043
2024-06-21 14:40:17,288 - INFO: Epoch: 6/10, Batch: 28/29, Batch_Loss_Train: 2.776
2024-06-21 14:40:17,513 - INFO: Epoch: 6/10, Batch: 29/29, Batch_Loss_Train: 3.861
2024-06-21 14:40:28,674 - INFO: 6/10 final results:
2024-06-21 14:40:28,674 - INFO: Training loss: 3.427.
2024-06-21 14:40:28,674 - INFO: Training MAE: 3.418.
2024-06-21 14:40:28,674 - INFO: Training MSE: 21.033.
2024-06-21 14:40:48,914 - INFO: Epoch: 6/10, Loss_train: 3.426683475231302, Loss_val: 3.639470404592054
2024-06-21 14:40:48,971 - INFO: Saved new best metric model for epoch 6.
2024-06-21 14:40:48,971 - INFO: Best internal validation val_loss: 3.639 at epoch: 6.
2024-06-21 14:40:48,971 - INFO: Epoch 7/10...
2024-06-21 14:40:48,971 - INFO: Learning rate: 4.6201611404555185e-05.
2024-06-21 14:40:48,971 - INFO: Batch size: 32.
2024-06-21 14:40:48,975 - INFO: Dataset:
2024-06-21 14:40:48,975 - INFO: Batch size:
2024-06-21 14:40:48,976 - INFO: Number of workers:
2024-06-21 14:40:50,257 - INFO: Epoch: 7/10, Batch: 1/29, Batch_Loss_Train: 3.153
2024-06-21 14:40:50,581 - INFO: Epoch: 7/10, Batch: 2/29, Batch_Loss_Train: 2.878
2024-06-21 14:40:50,984 - INFO: Epoch: 7/10, Batch: 3/29, Batch_Loss_Train: 3.570
2024-06-21 14:40:51,306 - INFO: Epoch: 7/10, Batch: 4/29, Batch_Loss_Train: 3.026
2024-06-21 14:40:51,722 - INFO: Epoch: 7/10, Batch: 5/29, Batch_Loss_Train: 3.107
2024-06-21 14:40:52,023 - INFO: Epoch: 7/10, Batch: 6/29, Batch_Loss_Train: 3.068
2024-06-21 14:40:52,408 - INFO: Epoch: 7/10, Batch: 7/29, Batch_Loss_Train: 2.880
2024-06-21 14:40:52,723 - INFO: Epoch: 7/10, Batch: 8/29, Batch_Loss_Train: 3.448
2024-06-21 14:40:53,139 - INFO: Epoch: 7/10, Batch: 9/29, Batch_Loss_Train: 3.396
2024-06-21 14:40:53,434 - INFO: Epoch: 7/10, Batch: 10/29, Batch_Loss_Train: 2.848
2024-06-21 14:40:53,814 - INFO: Epoch: 7/10, Batch: 11/29, Batch_Loss_Train: 2.691
2024-06-21 14:40:54,433 - INFO: Epoch: 7/10, Batch: 12/29, Batch_Loss_Train: 2.832
2024-06-21 14:40:54,869 - INFO: Epoch: 7/10, Batch: 13/29, Batch_Loss_Train: 2.676
2024-06-21 14:40:55,175 - INFO: Epoch: 7/10, Batch: 14/29, Batch_Loss_Train: 2.720
2024-06-21 14:40:55,575 - INFO: Epoch: 7/10, Batch: 15/29, Batch_Loss_Train: 2.950
2024-06-21 14:40:55,879 - INFO: Epoch: 7/10, Batch: 16/29, Batch_Loss_Train: 2.757
2024-06-21 14:40:56,306 - INFO: Epoch: 7/10, Batch: 17/29, Batch_Loss_Train: 2.522
2024-06-21 14:40:56,609 - INFO: Epoch: 7/10, Batch: 18/29, Batch_Loss_Train: 3.123
2024-06-21 14:40:56,999 - INFO: Epoch: 7/10, Batch: 19/29, Batch_Loss_Train: 2.772
2024-06-21 14:40:57,299 - INFO: Epoch: 7/10, Batch: 20/29, Batch_Loss_Train: 3.094
2024-06-21 14:40:57,719 - INFO: Epoch: 7/10, Batch: 21/29, Batch_Loss_Train: 2.329
2024-06-21 14:40:58,024 - INFO: Epoch: 7/10, Batch: 22/29, Batch_Loss_Train: 2.614
2024-06-21 14:40:58,407 - INFO: Epoch: 7/10, Batch: 23/29, Batch_Loss_Train: 2.713
2024-06-21 14:40:58,711 - INFO: Epoch: 7/10, Batch: 24/29, Batch_Loss_Train: 3.064
2024-06-21 14:40:59,140 - INFO: Epoch: 7/10, Batch: 25/29, Batch_Loss_Train: 3.248
2024-06-21 14:40:59,441 - INFO: Epoch: 7/10, Batch: 26/29, Batch_Loss_Train: 3.134
2024-06-21 14:40:59,812 - INFO: Epoch: 7/10, Batch: 27/29, Batch_Loss_Train: 2.789
2024-06-21 14:41:00,112 - INFO: Epoch: 7/10, Batch: 28/29, Batch_Loss_Train: 3.018
2024-06-21 14:41:00,320 - INFO: Epoch: 7/10, Batch: 29/29, Batch_Loss_Train: 2.672
2024-06-21 14:41:11,043 - INFO: 7/10 final results:
2024-06-21 14:41:11,044 - INFO: Training loss: 2.934.
2024-06-21 14:41:11,044 - INFO: Training MAE: 2.939.
2024-06-21 14:41:11,044 - INFO: Training MSE: 15.779.
2024-06-21 14:41:31,842 - INFO: Epoch: 7/10, Loss_train: 2.9342086150728424, Loss_val: 3.2305397494085906
2024-06-21 14:41:31,899 - INFO: Saved new best metric model for epoch 7.
2024-06-21 14:41:31,900 - INFO: Best internal validation val_loss: 3.231 at epoch: 7.
2024-06-21 14:41:31,900 - INFO: Epoch 8/10...
2024-06-21 14:41:31,900 - INFO: Learning rate: 4.6201611404555185e-05.
2024-06-21 14:41:31,900 - INFO: Batch size: 32.
2024-06-21 14:41:31,903 - INFO: Dataset:
2024-06-21 14:41:31,904 - INFO: Batch size:
2024-06-21 14:41:31,904 - INFO: Number of workers:
2024-06-21 14:41:33,173 - INFO: Epoch: 8/10, Batch: 1/29, Batch_Loss_Train: 2.649
2024-06-21 14:41:33,504 - INFO: Epoch: 8/10, Batch: 2/29, Batch_Loss_Train: 2.642
2024-06-21 14:41:33,930 - INFO: Epoch: 8/10, Batch: 3/29, Batch_Loss_Train: 3.082
2024-06-21 14:41:34,257 - INFO: Epoch: 8/10, Batch: 4/29, Batch_Loss_Train: 3.080
2024-06-21 14:41:34,658 - INFO: Epoch: 8/10, Batch: 5/29, Batch_Loss_Train: 2.586
2024-06-21 14:41:34,975 - INFO: Epoch: 8/10, Batch: 6/29, Batch_Loss_Train: 2.734
2024-06-21 14:41:35,382 - INFO: Epoch: 8/10, Batch: 7/29, Batch_Loss_Train: 2.995
2024-06-21 14:41:35,702 - INFO: Epoch: 8/10, Batch: 8/29, Batch_Loss_Train: 2.115
2024-06-21 14:41:36,081 - INFO: Epoch: 8/10, Batch: 9/29, Batch_Loss_Train: 2.534
2024-06-21 14:41:36,390 - INFO: Epoch: 8/10, Batch: 10/29, Batch_Loss_Train: 3.074
2024-06-21 14:41:36,771 - INFO: Epoch: 8/10, Batch: 11/29, Batch_Loss_Train: 2.491
2024-06-21 14:41:37,091 - INFO: Epoch: 8/10, Batch: 12/29, Batch_Loss_Train: 2.346
2024-06-21 14:41:37,494 - INFO: Epoch: 8/10, Batch: 13/29, Batch_Loss_Train: 2.567
2024-06-21 14:41:37,814 - INFO: Epoch: 8/10, Batch: 14/29, Batch_Loss_Train: 2.211
2024-06-21 14:41:38,213 - INFO: Epoch: 8/10, Batch: 15/29, Batch_Loss_Train: 3.035
2024-06-21 14:41:38,527 - INFO: Epoch: 8/10, Batch: 16/29, Batch_Loss_Train: 2.752
2024-06-21 14:41:38,915 - INFO: Epoch: 8/10, Batch: 17/29, Batch_Loss_Train: 2.609
2024-06-21 14:41:39,228 - INFO: Epoch: 8/10, Batch: 18/29, Batch_Loss_Train: 2.420
2024-06-21 14:41:39,612 - INFO: Epoch: 8/10, Batch: 19/29, Batch_Loss_Train: 2.335
2024-06-21 14:41:39,926 - INFO: Epoch: 8/10, Batch: 20/29, Batch_Loss_Train: 2.081
2024-06-21 14:41:40,317 - INFO: Epoch: 8/10, Batch: 21/29, Batch_Loss_Train: 2.372
2024-06-21 14:41:40,638 - INFO: Epoch: 8/10, Batch: 22/29, Batch_Loss_Train: 2.251
2024-06-21 14:41:41,040 - INFO: Epoch: 8/10, Batch: 23/29, Batch_Loss_Train: 2.525
2024-06-21 14:41:41,361 - INFO: Epoch: 8/10, Batch: 24/29, Batch_Loss_Train: 2.692
2024-06-21 14:41:41,756 - INFO: Epoch: 8/10, Batch: 25/29, Batch_Loss_Train: 2.317
2024-06-21 14:41:42,070 - INFO: Epoch: 8/10, Batch: 26/29, Batch_Loss_Train: 2.509
2024-06-21 14:41:42,454 - INFO: Epoch: 8/10, Batch: 27/29, Batch_Loss_Train: 2.121
2024-06-21 14:41:42,767 - INFO: Epoch: 8/10, Batch: 28/29, Batch_Loss_Train: 2.137
2024-06-21 14:41:42,976 - INFO: Epoch: 8/10, Batch: 29/29, Batch_Loss_Train: 2.019
2024-06-21 14:41:53,988 - INFO: 8/10 final results:
2024-06-21 14:41:53,988 - INFO: Training loss: 2.527.
2024-06-21 14:41:53,988 - INFO: Training MAE: 2.537.
2024-06-21 14:41:53,988 - INFO: Training MSE: 12.038.
2024-06-21 14:42:14,627 - INFO: Epoch: 8/10, Loss_train: 2.527040489788713, Loss_val: 2.5411848364205194
2024-06-21 14:42:14,684 - INFO: Saved new best metric model for epoch 8.
2024-06-21 14:42:14,684 - INFO: Best internal validation val_loss: 2.541 at epoch: 8.
2024-06-21 14:42:14,684 - INFO: Epoch 9/10...
2024-06-21 14:42:14,684 - INFO: Learning rate: 4.6201611404555185e-05.
2024-06-21 14:42:14,684 - INFO: Batch size: 32.
2024-06-21 14:42:14,688 - INFO: Dataset:
2024-06-21 14:42:14,688 - INFO: Batch size:
2024-06-21 14:42:14,688 - INFO: Number of workers:
2024-06-21 14:42:15,972 - INFO: Epoch: 9/10, Batch: 1/29, Batch_Loss_Train: 2.080
2024-06-21 14:42:16,285 - INFO: Epoch: 9/10, Batch: 2/29, Batch_Loss_Train: 2.280
2024-06-21 14:42:16,694 - INFO: Epoch: 9/10, Batch: 3/29, Batch_Loss_Train: 2.055
2024-06-21 14:42:17,021 - INFO: Epoch: 9/10, Batch: 4/29, Batch_Loss_Train: 2.693
2024-06-21 14:42:17,451 - INFO: Epoch: 9/10, Batch: 5/29, Batch_Loss_Train: 2.032
2024-06-21 14:42:17,752 - INFO: Epoch: 9/10, Batch: 6/29, Batch_Loss_Train: 1.917
2024-06-21 14:42:18,146 - INFO: Epoch: 9/10, Batch: 7/29, Batch_Loss_Train: 2.040
2024-06-21 14:42:18,467 - INFO: Epoch: 9/10, Batch: 8/29, Batch_Loss_Train: 2.257
2024-06-21 14:42:18,898 - INFO: Epoch: 9/10, Batch: 9/29, Batch_Loss_Train: 1.504
2024-06-21 14:42:19,198 - INFO: Epoch: 9/10, Batch: 10/29, Batch_Loss_Train: 2.537
2024-06-21 14:42:19,584 - INFO: Epoch: 9/10, Batch: 11/29, Batch_Loss_Train: 2.042
2024-06-21 14:42:19,908 - INFO: Epoch: 9/10, Batch: 12/29, Batch_Loss_Train: 1.909
2024-06-21 14:42:20,351 - INFO: Epoch: 9/10, Batch: 13/29, Batch_Loss_Train: 2.285
2024-06-21 14:42:20,662 - INFO: Epoch: 9/10, Batch: 14/29, Batch_Loss_Train: 2.111
2024-06-21 14:42:21,066 - INFO: Epoch: 9/10, Batch: 15/29, Batch_Loss_Train: 1.938
2024-06-21 14:42:21,385 - INFO: Epoch: 9/10, Batch: 16/29, Batch_Loss_Train: 1.950
2024-06-21 14:42:21,821 - INFO: Epoch: 9/10, Batch: 17/29, Batch_Loss_Train: 1.816
2024-06-21 14:42:22,128 - INFO: Epoch: 9/10, Batch: 18/29, Batch_Loss_Train: 1.885
2024-06-21 14:42:22,517 - INFO: Epoch: 9/10, Batch: 19/29, Batch_Loss_Train: 2.093
2024-06-21 14:42:22,831 - INFO: Epoch: 9/10, Batch: 20/29, Batch_Loss_Train: 2.092
2024-06-21 14:42:23,258 - INFO: Epoch: 9/10, Batch: 21/29, Batch_Loss_Train: 1.884
2024-06-21 14:42:23,569 - INFO: Epoch: 9/10, Batch: 22/29, Batch_Loss_Train: 1.951
2024-06-21 14:42:23,971 - INFO: Epoch: 9/10, Batch: 23/29, Batch_Loss_Train: 2.075
2024-06-21 14:42:24,296 - INFO: Epoch: 9/10, Batch: 24/29, Batch_Loss_Train: 2.201
2024-06-21 14:42:24,726 - INFO: Epoch: 9/10, Batch: 25/29, Batch_Loss_Train: 2.147
2024-06-21 14:42:25,029 - INFO: Epoch: 9/10, Batch: 26/29, Batch_Loss_Train: 1.734
2024-06-21 14:42:25,421 - INFO: Epoch: 9/10, Batch: 27/29, Batch_Loss_Train: 1.786
2024-06-21 14:42:25,738 - INFO: Epoch: 9/10, Batch: 28/29, Batch_Loss_Train: 2.229
2024-06-21 14:42:25,961 - INFO: Epoch: 9/10, Batch: 29/29, Batch_Loss_Train: 1.947
2024-06-21 14:42:37,147 - INFO: 9/10 final results:
2024-06-21 14:42:37,147 - INFO: Training loss: 2.051.
2024-06-21 14:42:37,147 - INFO: Training MAE: 2.053.
2024-06-21 14:42:37,147 - INFO: Training MSE: 8.053.
2024-06-21 14:42:57,577 - INFO: Epoch: 9/10, Loss_train: 2.050644508723555, Loss_val: 2.3849520025582147
2024-06-21 14:42:57,635 - INFO: Saved new best metric model for epoch 9.
2024-06-21 14:42:57,635 - INFO: Best internal validation val_loss: 2.385 at epoch: 9.
2024-06-21 14:42:57,635 - INFO: Epoch 10/10...
2024-06-21 14:42:57,635 - INFO: Learning rate: 4.6201611404555185e-05.
2024-06-21 14:42:57,635 - INFO: Batch size: 32.
2024-06-21 14:42:57,639 - INFO: Dataset:
2024-06-21 14:42:57,639 - INFO: Batch size:
2024-06-21 14:42:57,639 - INFO: Number of workers:
2024-06-21 14:42:58,919 - INFO: Epoch: 10/10, Batch: 1/29, Batch_Loss_Train: 2.086
2024-06-21 14:42:59,258 - INFO: Epoch: 10/10, Batch: 2/29, Batch_Loss_Train: 1.669
2024-06-21 14:42:59,703 - INFO: Epoch: 10/10, Batch: 3/29, Batch_Loss_Train: 1.794
2024-06-21 14:43:00,031 - INFO: Epoch: 10/10, Batch: 4/29, Batch_Loss_Train: 1.734
2024-06-21 14:43:00,442 - INFO: Epoch: 10/10, Batch: 5/29, Batch_Loss_Train: 1.670
2024-06-21 14:43:00,759 - INFO: Epoch: 10/10, Batch: 6/29, Batch_Loss_Train: 1.767
2024-06-21 14:43:01,162 - INFO: Epoch: 10/10, Batch: 7/29, Batch_Loss_Train: 1.842
2024-06-21 14:43:01,481 - INFO: Epoch: 10/10, Batch: 8/29, Batch_Loss_Train: 2.078
2024-06-21 14:43:01,872 - INFO: Epoch: 10/10, Batch: 9/29, Batch_Loss_Train: 2.168
2024-06-21 14:43:02,181 - INFO: Epoch: 10/10, Batch: 10/29, Batch_Loss_Train: 1.743
2024-06-21 14:43:02,574 - INFO: Epoch: 10/10, Batch: 11/29, Batch_Loss_Train: 1.904
2024-06-21 14:43:02,895 - INFO: Epoch: 10/10, Batch: 12/29, Batch_Loss_Train: 1.463
2024-06-21 14:43:03,310 - INFO: Epoch: 10/10, Batch: 13/29, Batch_Loss_Train: 1.816
2024-06-21 14:43:03,631 - INFO: Epoch: 10/10, Batch: 14/29, Batch_Loss_Train: 1.729
2024-06-21 14:43:04,042 - INFO: Epoch: 10/10, Batch: 15/29, Batch_Loss_Train: 2.033
2024-06-21 14:43:04,355 - INFO: Epoch: 10/10, Batch: 16/29, Batch_Loss_Train: 1.580
2024-06-21 14:43:04,756 - INFO: Epoch: 10/10, Batch: 17/29, Batch_Loss_Train: 2.373
2024-06-21 14:43:05,070 - INFO: Epoch: 10/10, Batch: 18/29, Batch_Loss_Train: 1.700
2024-06-21 14:43:05,467 - INFO: Epoch: 10/10, Batch: 19/29, Batch_Loss_Train: 1.742
2024-06-21 14:43:05,776 - INFO: Epoch: 10/10, Batch: 20/29, Batch_Loss_Train: 1.946
2024-06-21 14:43:06,175 - INFO: Epoch: 10/10, Batch: 21/29, Batch_Loss_Train: 1.719
2024-06-21 14:43:06,494 - INFO: Epoch: 10/10, Batch: 22/29, Batch_Loss_Train: 2.119
2024-06-21 14:43:06,892 - INFO: Epoch: 10/10, Batch: 23/29, Batch_Loss_Train: 1.755
2024-06-21 14:43:07,210 - INFO: Epoch: 10/10, Batch: 24/29, Batch_Loss_Train: 2.457
2024-06-21 14:43:07,601 - INFO: Epoch: 10/10, Batch: 25/29, Batch_Loss_Train: 1.833
2024-06-21 14:43:07,912 - INFO: Epoch: 10/10, Batch: 26/29, Batch_Loss_Train: 1.900
2024-06-21 14:43:08,291 - INFO: Epoch: 10/10, Batch: 27/29, Batch_Loss_Train: 1.822
2024-06-21 14:43:08,602 - INFO: Epoch: 10/10, Batch: 28/29, Batch_Loss_Train: 1.865
2024-06-21 14:43:08,810 - INFO: Epoch: 10/10, Batch: 29/29, Batch_Loss_Train: 1.534
2024-06-21 14:43:19,803 - INFO: 10/10 final results:
2024-06-21 14:43:19,803 - INFO: Training loss: 1.857.
2024-06-21 14:43:19,803 - INFO: Training MAE: 1.863.
2024-06-21 14:43:19,803 - INFO: Training MSE: 6.669.
2024-06-21 14:43:40,719 - INFO: Epoch: 10/10, Loss_train: 1.8565950763636623, Loss_val: 1.863814037421654
2024-06-21 14:43:40,778 - INFO: Saved new best metric model for epoch 10.
2024-06-21 14:43:40,778 - INFO: Best internal validation val_loss: 1.864 at epoch: 10.
2024-06-21 14:44:25,367 - INFO: Experiment has been saved in 20240621_144425_410_Dual_DCNN_LReLu_1_10_tr_1.652_val_1.864_test_2.979_avg_tr_2.131_val_2.337_test_3.144 folder.
2024-06-21 14:44:25,367 - INFO: Elapsed time: 1169.514 seconds.
2024-06-21 14:44:25,367 - INFO: DONE!
