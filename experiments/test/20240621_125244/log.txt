2024-06-21 12:52:44,184 - INFO: Device: cuda.
2024-06-21 12:52:44,184 - INFO: Torch version: 2.0.1+cu117.
2024-06-21 12:52:44,184 - INFO: Torch.backends.cudnn.benchmark: True.
2024-06-21 12:52:44,184 - INFO: Model name: Dual_DCNN_LReLu
2024-06-21 12:52:44,184 - INFO: Seed: 4
2024-06-21 12:52:44,184 - INFO: 42 patients have been found in the data directory.
2024-06-21 12:52:44,224 - INFO: Train set contains 32 patients.
2024-06-21 12:52:44,224 - INFO: Val set contains 5 patients.
2024-06-21 12:52:44,224 - INFO: Test set contains 5 patients.
2024-06-21 12:52:44,224 - INFO: Fold: 0
2024-06-21 12:52:44,225 - INFO: Performing 2-fold Cross Validation.
2024-06-21 12:52:44,225 - INFO: Train Set: 910/1970, percent: 0.462
2024-06-21 12:52:44,225 - INFO: Val Set: 910/1970, percent: 0.462
2024-06-21 12:52:44,225 - INFO: Test Set: 150/1970, percent: 0.076
2024-06-21 12:52:44,356 - INFO: To_device: False.
2024-06-21 12:52:44,357 - INFO: Transformers have been made successfully.
2024-06-21 12:52:44,358 - INFO: Dataset type: cache.
2024-06-21 12:52:44,358 - INFO: Dataloader type: standard.
2024-06-21 12:54:34,846 - INFO: Train dataloader arguments.
2024-06-21 12:54:34,846 - INFO: 	Batch_size: 32.
2024-06-21 12:54:34,846 - INFO: 	Shuffle: True.
2024-06-21 12:54:34,846 - INFO: 	Sampler: None.
2024-06-21 12:54:34,846 - INFO: 	Num_workers: 4.
2024-06-21 12:54:34,847 - INFO: 	Drop_last: False.
2024-06-21 12:54:35,018 - INFO: Dual_DCNN_LReLU(
  (conv_blocks_fixed): ModuleList(
    (0): conv_block_two(
      (pad1): conv3d_padding_same()
      (conv1): Conv3d(1, 8, kernel_size=(1, 7, 7), stride=(2, 2, 2))
      (norm1): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activation1): LeakyReLU(negative_slope=0.1)
      (pad2): conv3d_padding_same()
      (conv2): Conv3d(8, 8, kernel_size=(1, 7, 7), stride=(1, 1, 1))
      (norm2): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activation2): LeakyReLU(negative_slope=0.1)
      (max_pooling): MaxPool3d(kernel_size=3, stride=1, padding=0, dilation=1, ceil_mode=False)
    )
    (1): conv_block_two(
      (pad1): conv3d_padding_same()
      (conv1): Conv3d(8, 8, kernel_size=(1, 5, 5), stride=(2, 2, 2))
      (norm1): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activation1): LeakyReLU(negative_slope=0.1)
      (pad2): conv3d_padding_same()
      (conv2): Conv3d(8, 8, kernel_size=(1, 5, 5), stride=(1, 1, 1))
      (norm2): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activation2): LeakyReLU(negative_slope=0.1)
      (max_pooling): MaxPool3d(kernel_size=3, stride=1, padding=0, dilation=1, ceil_mode=False)
    )
    (2): conv_block_two(
      (pad1): conv3d_padding_same()
      (conv1): Conv3d(8, 16, kernel_size=(1, 4, 4), stride=(1, 1, 1))
      (norm1): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activation1): LeakyReLU(negative_slope=0.1)
      (pad2): conv3d_padding_same()
      (conv2): Conv3d(16, 16, kernel_size=(1, 4, 4), stride=(1, 1, 1))
      (norm2): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activation2): LeakyReLU(negative_slope=0.1)
      (max_pooling): MaxPool3d(kernel_size=3, stride=1, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (conv_blocks_moving): ModuleList(
    (0): conv_block_two(
      (pad1): conv3d_padding_same()
      (conv1): Conv3d(1, 8, kernel_size=(1, 7, 7), stride=(2, 2, 2))
      (norm1): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activation1): LeakyReLU(negative_slope=0.1)
      (pad2): conv3d_padding_same()
      (conv2): Conv3d(8, 8, kernel_size=(1, 7, 7), stride=(1, 1, 1))
      (norm2): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activation2): LeakyReLU(negative_slope=0.1)
      (max_pooling): MaxPool3d(kernel_size=3, stride=1, padding=0, dilation=1, ceil_mode=False)
    )
    (1): conv_block_two(
      (pad1): conv3d_padding_same()
      (conv1): Conv3d(8, 8, kernel_size=(1, 5, 5), stride=(2, 2, 2))
      (norm1): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activation1): LeakyReLU(negative_slope=0.1)
      (pad2): conv3d_padding_same()
      (conv2): Conv3d(8, 8, kernel_size=(1, 5, 5), stride=(1, 1, 1))
      (norm2): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activation2): LeakyReLU(negative_slope=0.1)
      (max_pooling): MaxPool3d(kernel_size=3, stride=1, padding=0, dilation=1, ceil_mode=False)
    )
    (2): conv_block_two(
      (pad1): conv3d_padding_same()
      (conv1): Conv3d(8, 16, kernel_size=(1, 4, 4), stride=(1, 1, 1))
      (norm1): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activation1): LeakyReLU(negative_slope=0.1)
      (pad2): conv3d_padding_same()
      (conv2): Conv3d(16, 16, kernel_size=(1, 4, 4), stride=(1, 1, 1))
      (norm2): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activation2): LeakyReLU(negative_slope=0.1)
      (max_pooling): MaxPool3d(kernel_size=3, stride=1, padding=0, dilation=1, ceil_mode=False)
    )
  )
  (linear_layers): ModuleList(
    (0): Dropout(p=0.35973448489278154, inplace=False)
    (1): Linear(in_features=1048576, out_features=32, bias=True)
  )
  (out_layer): Output(
    in_features=32, out_features=3, bias=True
    (fc): Linear(in_features=32, out_features=3, bias=True)
  )
)
2024-06-21 12:54:35,894 - INFO: Weight init name: kaiming_uniform.
2024-06-21 12:54:38,856 - INFO: Number of training iterations per epoch: 29.
2024-06-21 12:54:38,857 - INFO: Epoch 1/10...
2024-06-21 12:54:38,857 - INFO: Learning rate: 0.002542355689225227.
2024-06-21 12:54:38,857 - INFO: Batch size: 32.
2024-06-21 12:54:38,857 - INFO: Dataset:
2024-06-21 12:54:38,857 - INFO: Batch size:
2024-06-21 12:54:38,857 - INFO: Number of workers:
2024-06-21 12:54:42,406 - INFO: Epoch: 1/10, Batch: 1/29, Batch_Loss_Train: 78.765
2024-06-21 12:54:43,005 - INFO: Epoch: 1/10, Batch: 2/29, Batch_Loss_Train: 62.098
2024-06-21 12:54:43,660 - INFO: Epoch: 1/10, Batch: 3/29, Batch_Loss_Train: 70.039
2024-06-21 12:54:44,240 - INFO: Epoch: 1/10, Batch: 4/29, Batch_Loss_Train: 74.273
2024-06-21 12:54:44,911 - INFO: Epoch: 1/10, Batch: 5/29, Batch_Loss_Train: 65.409
2024-06-21 12:54:45,484 - INFO: Epoch: 1/10, Batch: 6/29, Batch_Loss_Train: 79.374
2024-06-21 12:54:46,131 - INFO: Epoch: 1/10, Batch: 7/29, Batch_Loss_Train: 659.936
2024-06-21 12:54:46,706 - INFO: Epoch: 1/10, Batch: 8/29, Batch_Loss_Train: 24710180.000
2024-06-21 12:54:47,572 - INFO: Epoch: 1/10, Batch: 9/29, Batch_Loss_Train: 2228797304897770510985723904.000
2024-06-21 12:54:48,007 - INFO: Epoch: 1/10, Batch: 10/29, Batch_Loss_Train: nan
2024-06-21 12:54:48,509 - INFO: Epoch: 1/10, Batch: 11/29, Batch_Loss_Train: nan
2024-06-21 12:54:48,951 - INFO: Epoch: 1/10, Batch: 12/29, Batch_Loss_Train: nan
2024-06-21 12:54:49,496 - INFO: Epoch: 1/10, Batch: 13/29, Batch_Loss_Train: nan
2024-06-21 12:54:49,936 - INFO: Epoch: 1/10, Batch: 14/29, Batch_Loss_Train: nan
